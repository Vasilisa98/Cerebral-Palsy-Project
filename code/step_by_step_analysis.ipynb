{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msk_modelling_python as msk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import opensim as osim\n",
    "from xml.etree import ElementTree as ET\n",
    "import c3d\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import xml.dom.minidom \n",
    "import scipy.signal as sig\n",
    "import neurokit2 as nk\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import scipy.stats as stats\n",
    "from scipy.interpolate import interp1d\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "one_dir_up = os.path.dirname(current_dir)\n",
    "print(one_dir_up)\n",
    "simulations_dir = os.path.join(one_dir_up, 'Simulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(simulations_dir, \"PC013\", \"trial3_r1\", \"Results_SO_and_MA\")\n",
    "file_mapping = {\n",
    "    '_MuscleAnalysis': 'MuscleAnalysis'\n",
    "}\n",
    "# loop through all files in the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        if any(substring in file for substring in file_mapping.keys()):\n",
    "            print(file)\n",
    "            new_file = file.replace(list(file_mapping.keys())[0], list(file_mapping.values())[0])\n",
    "            print(os.path.join(root, file))\n",
    "            \n",
    "            os.rename(os.path.join(root, file), os.path.join(root, new_file))\n",
    "            print(f\"Renamed {file} to {new_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class File:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.name = os.path.basename(path)\n",
    "        self.extension = os.path.splitext(path)[1]\n",
    "        \n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"\\033[93mFile not found: {path}\\033[0m\")\n",
    "            return        \n",
    "        \n",
    "        try:\n",
    "            endheader_line = self.find_file_endheader_line(path)\n",
    "        except:\n",
    "            print(f\"Error finding endheader line for file: {path}\")\n",
    "            endheader_line = 0\n",
    "        # Read file based on extension\n",
    "        try:\n",
    "            if self.extension == '.csv':\n",
    "                self.data = msk.pd.read_csv(path)\n",
    "            elif self.extension == '.json':\n",
    "                self.data = msk.bops.import_json_file(path)\n",
    "            elif self.extension == '.xml':\n",
    "                self.data = msk.bops.XMLTools.load(path)\n",
    "            else:\n",
    "                try:\n",
    "                    self.data = msk.pd.read_csv(path, sep=\"\\t\", skiprows=endheader_line)\n",
    "                except:\n",
    "                    self.data = None\n",
    "                    \n",
    "            # add time range for the data\n",
    "            try:\n",
    "                self.time_range = [self.data['time'].iloc[0], self.data['time'].iloc[-1]]\n",
    "                try:\n",
    "                    self.time_range = [self.data['Time'].iloc[0], self.data['Time'].iloc[-1]]\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                self.time_range = None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {path}\")\n",
    "            print(e)\n",
    "            self.data = None\n",
    "            self.time_range = None\n",
    "    def find_file_endheader_line(self, path):\n",
    "        with open(path, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if 'endheader' in line:\n",
    "                    return i + 1\n",
    "        return 0    \n",
    "    \n",
    "class Trial:\n",
    "    '''\n",
    "    Class to store trial information and file paths, and export files to OpenSim format\n",
    "    \n",
    "    Inputs: trial_path (str) - path to the trial folder\n",
    "    \n",
    "    Attributes:\n",
    "    path (str) - path to the trial folder\n",
    "    name (str) - name of the trial folder\n",
    "    og_c3d (str) - path to the original c3d file\n",
    "    c3d (str) - path to the c3d file in the trial folder\n",
    "    markers (str) - path to the marker trc file\n",
    "    grf (str) - path to the ground reaction force mot file\n",
    "    ...\n",
    "    \n",
    "    Methods: use dir(Trial) to see all methods\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, trial_path):        \n",
    "        self.path = trial_path\n",
    "        self.name = os.path.basename(self.path)\n",
    "        self.subject = os.path.basename(os.path.dirname(self.path))\n",
    "        self.c3d = os.path.join(os.path.dirname(self.path), self.name + '.c3d')\n",
    "        self.markers = File(os.path.join(self.path,'markers_experimental.trc'))\n",
    "        self.grf = File(os.path.join(self.path,'Visual3d_SIMM_grf.mot'))\n",
    "        self.emg_csv = File(os.path.join(self.path,'processed_emg_signals.csv'))\n",
    "        self.emg = File(os.path.join(self.path,'processed_emg_signals.mot'))\n",
    "        self.ik = File(os.path.join(self.path,'Visual3d_SIMM_input.mot'))\n",
    "        self.id = File(os.path.join(self.path,'inverse_dynamics.sto'))\n",
    "        self.so_force = File(os.path.join(self.path,'Results_SO_and_MA', f'{self.subject}_StaticOptimization_force.sto'))\n",
    "        self.so_activation = File(os.path.join(self.path, 'Results_SO_and_MA', f'{self.subject}_StaticOptimization_activation.sto'))\n",
    "        self.jra = File(os.path.join(self.path,'joint_reacton_loads.sto'))\n",
    "        \n",
    "        # load muscle analysis files\n",
    "        self.ma_targets = ['_MomentArm_', '_Length.sto']\n",
    "        self.ma_files = []\n",
    "        try:\n",
    "            files = os.listdir(os.path.join(self.path, 'Results_SO_and_MA'))\n",
    "            for file in files:\n",
    "                if file.__contains__(self.ma_targets[0]) or file.__contains__(self.ma_targets[1]):\n",
    "                    self.ma_files.append(File(os.path.join(self.path, 'Results_SO_and_MA', file)))\n",
    "        except:\n",
    "            self.ma_files = None\n",
    "                    \n",
    "        # settings files\n",
    "        self.grf_xml = File(os.path.join(self.path,'GRF_Setup.xml'))\n",
    "        self.actuators_so = File(os.path.join(self.path,'actuators_SO.xml'))\n",
    "        \n",
    "        self.settings_json = File(os.path.join(self.path,'settings.json'))\n",
    "        \n",
    "        # CEINMS files\n",
    "        self.ceinms_cal_setup = File(os.path.join(self.path,'ceinms','calibrationSetup.xml'))\n",
    "        self.ceinms_cal_cfg = File(os.path.join(self.path,'ceinms','calibrationCfg.xml'))\n",
    "        self.ceinms_trial = File(os.path.join(self.path,'ceinms','trial.xml'))\n",
    "        self.ceinms_uncalibrated_subject = File(os.path.join(self.path,'ceinms','uncalibratedSubject.xml'))\n",
    "        self.ceinms_excitation_generator = File(os.path.join(self.path,'ceinms','excitationGenerator.xml'))\n",
    "        self.ceinms_execution_setup = File(os.path.join(self.path, 'ceinms', 'executionSetup.xml'))\n",
    "        self.ceinms_execution_cfg = File(os.path.join(self.path, 'ceinms', 'executionCfg.xml'))\n",
    "\n",
    "                              \n",
    "    def check_files(self):\n",
    "        '''\n",
    "        Output: True if all files exist, False if any file is missing\n",
    "        '''\n",
    "        files = self.__dict__.values()\n",
    "        all_files_exist = True\n",
    "        for file in files:\n",
    "            try:\n",
    "                if not os.path.isfile(file):\n",
    "                    print('File not found: ' + file)\n",
    "                    all_files_exist = False\n",
    "            except:\n",
    "                pass\n",
    "        return all_files_exist\n",
    "    \n",
    "    def header_mot(self,df,name):\n",
    "\n",
    "            num_rows = len(df)\n",
    "            num_cols = len(df.columns) \n",
    "            inital_time = df['Time'].iloc[0]\n",
    "            final_time = df['Time'].iloc[-1]\n",
    "            df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "            return f'name {name}\\n datacolumns {num_cols}\\n datarows {num_rows}\\n range {df_range} \\n endheader'\n",
    "        \n",
    "    def csv_to_mot(self):\n",
    "        \n",
    "        emg_data = msk.bops.pd.read_csv(self.emg_csv)\n",
    "\n",
    "        fs = int(1/(emg_data['time'][1] - emg_data['time'][0]))\n",
    "\n",
    "        time = emg_data['time']\n",
    "\n",
    "        # start time from new time point\n",
    "        start_time = time.iloc[0]\n",
    "        end_time = time.iloc[-1] - time.iloc[0] + start_time\n",
    "\n",
    "        num_samples = len(emg_data)\n",
    "        #num_samples = int((end_time - start_time) / (1/fs))\n",
    "        new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "        emg_data['time'] = new_time\n",
    "\n",
    "        # Define a new file path \n",
    "        new_file_path = os.path.join(self.emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "        # Save the modified DataFrame\n",
    "        emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "        # save to mot\n",
    "        header = self.header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "        mot_path = new_file_path.replace('.csv','.mot')\n",
    "        with open(mot_path, 'w') as f:\n",
    "            f.write(header + '\\n')  \n",
    "            # print column names \n",
    "            f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "            for index, row in emg_data.iterrows():\n",
    "                f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "        \n",
    "        print(f\"File saved: {mot_path}\")\n",
    "\n",
    "    def create_settings_json(self, overwrite=False):\n",
    "        if os.path.isfile(self.settings_json) and not overwrite:\n",
    "            print('settings.json already exists')\n",
    "            return\n",
    "        \n",
    "        settings_dict = self.__dict__\n",
    "        msk.bops.save_json_file(settings_dict, self.settings_json)\n",
    "        print('trial settings.json created in ' + self.path)\n",
    "    \n",
    "    def exportC3D(self):\n",
    "        msk.bops.c3d_osim_export(self.og_c3d) \n",
    "\n",
    "    def change_grf_xml_path(self):\n",
    "\n",
    "        try:\n",
    "            self.tree = ET.parse(self.grf_xml.path)\n",
    "            self.root = self.tree.getroot()\n",
    "            self.root.find('.//datafile').text = self.grf.path\n",
    "            \n",
    "            self.tree.write(self.grf_xml.path)\n",
    "            \n",
    "            print(f\"GRF file path updated in {self.grf_xml.path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading XML file: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_json_file(self, data, jsonFilePath):\n",
    "        data = data.__dict__\n",
    "\n",
    "        with open(jsonFilePath, 'w') as f:\n",
    "            msk.bops.json.dump(data, f, indent=4)\n",
    "\n",
    "        json_data = msk.bops.import_json_file(jsonFilePath)\n",
    "        return json_data\n",
    "    \n",
    "    def to_json(self):\n",
    "        msk.bops.save_json_file(self.__dict__, jsonFilePath = self.settings_json)\n",
    "        print('settings.json created in ' + self.settings_json)\n",
    "    \n",
    "    def run_IK(osim_modelPath, trc_file, resultsDir):\n",
    "        '''\n",
    "        Function to run Inverse Kinematics using the OpenSim API.\n",
    "        \n",
    "        Inputs:\n",
    "                osim_modelPath(str): path to the OpenSim model file\n",
    "                trc_file(str): path to the TRC file\n",
    "                resultsDir(str): path to the directory where the results will be saved\n",
    "        '''\n",
    "\n",
    "        # Load the TRC file\n",
    "        import pdb; pdb.set_trace()\n",
    "        tuple_data = msk.bops.import_trc_file(trc_file)\n",
    "        df = pd.DataFrame.from_records(tuple_data, columns=[x[0] for x in tuple_data])\n",
    "        column_names = [x[0] for x in tuple_data]\n",
    "        if len(set(column_names)) != len(column_names):\n",
    "            print(\"Error: Duplicate column names found.\")\n",
    "        # Load the model\n",
    "        osimModel = osim.Model(osim_modelPath)                              \n",
    "        state = osimModel.initSystem()\n",
    "\n",
    "        # Define the time range for the analysis\n",
    "        \n",
    "        initialTime = msk.TRCData.getIndependentColumn()\n",
    "        finalTime = msk.TRCData.getLastTime()\n",
    "\n",
    "        # Create the inverse kinematics tool\n",
    "        ikTool = osim.InverseKinematicsTool()\n",
    "        ikTool.setModel(osimModel)\n",
    "        ikTool.setStartTime(initialTime)\n",
    "        ikTool.setEndTime(finalTime)\n",
    "        ikTool.setMarkerDataFileName(trc_file)\n",
    "        ikTool.setResultsDir(resultsDir)\n",
    "        ikTool.set_accuracy(1e-6)\n",
    "        ikTool.setOutputMotionFileName(os.path.join(resultsDir, \"ik.mot\"))\n",
    "\n",
    "        # print setup\n",
    "        ikTool.printToXML(os.path.join(resultsDir, \"ik_setup.xml\"))         \n",
    "\n",
    "        # Run inverse kinematics\n",
    "        print(\"running ik...\")                                             \n",
    "        ikTool.run()\n",
    "\n",
    "    def run_inverse_kinematics(model_file, marker_file, output_motion_file):\n",
    "        # Load model and create an InverseKinematicsTool\n",
    "        model = osim.Model(model_file)\n",
    "        ik_tool = osim.InverseKinematicsTool()\n",
    "\n",
    "        # Set the model for the InverseKinematicsTool\n",
    "        ik_tool.setModel(model)\n",
    "\n",
    "        # Set the marker data file for the InverseKinematicsTool\n",
    "        ik_tool.setMarkerDataFileName(marker_file)\n",
    "\n",
    "        # Specify output motion file\n",
    "        ik_tool.setOutputMotionFileName(output_motion_file)\n",
    "\n",
    "        # Save setup file\n",
    "        ik_tool.printToXML('setup_ik.xml')\n",
    "\n",
    "        # Run Inverse Kinematics\n",
    "        ik_tool.run()\n",
    "\n",
    "    def run_ID(self, osim_modelPath, coordinates_file, external_loads_file, output_file, LowpassCutoffFrequency=6, run_tool=True):\n",
    "        \n",
    "        try: \n",
    "            model = osim.Model(osim_modelPath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {osim_modelPath}\")\n",
    "            print(e)\n",
    "            return\n",
    "        \n",
    "        results_folder = os.path.dirname(output_file)\n",
    "        \n",
    "        # Setup for excluding muscles from ID\n",
    "        exclude = osim.ArrayStr()\n",
    "        exclude.append(\"Muscles\")\n",
    "        # Setup for setting time range\n",
    "        IKData = osim.Storage(coordinates_file)\n",
    "\n",
    "        # Create inverse dynamics tool, set parameters and run\n",
    "        id_tool = osim.InverseDynamicsTool()\n",
    "        id_tool.setModel(model)\n",
    "        id_tool.setCoordinatesFileName(coordinates_file)\n",
    "        id_tool.setExternalLoadsFileName(external_loads_file)\n",
    "        id_tool.setOutputGenForceFileName(output_file)\n",
    "        id_tool.setLowpassCutoffFrequency(LowpassCutoffFrequency)\n",
    "        id_tool.setStartTime(IKData.getFirstTime())\n",
    "        id_tool.setEndTime(IKData.getLastTime())\n",
    "        id_tool.setExcludedForces(exclude)\n",
    "        id_tool.setResultsDir(results_folder)\n",
    "        id_tool.printToXML(os.path.join(results_folder, \"setup_ID.xml\"))\n",
    "        \n",
    "        if run_tool:\n",
    "            id_tool.run()\n",
    "    \n",
    "\n",
    "    # CREATE CEINMS XML files\n",
    "    def create_calibration_setup(self, save_path = None):\n",
    "            root = ET.Element(\"ceinmsCalibration\")\n",
    "            \n",
    "            subject_file = ET.SubElement(root, \"subjectFile\")\n",
    "            subject_file.text = \".\\\\uncalibratedSubject.xml\"\n",
    "            \n",
    "            excitation_generator_file = ET.SubElement(root, \"excitationGeneratorFile\")\n",
    "            excitation_generator_file.text = \".\\\\excitationGenerator.xml\"\n",
    "            \n",
    "            calibration_file = ET.SubElement(root, \"calibrationFile\")\n",
    "            calibration_file.text = \".\\\\calibrationCfg.xml\"\n",
    "            \n",
    "            output_subject_file = ET.SubElement(root, \"outputSubjectFile\")\n",
    "            output_subject_file.text = \".\\\\calibratedSubject.xml\"\n",
    "            \n",
    "            tree = ET.ElementTree(root)\n",
    "            if save_path is not None:\n",
    "                save_pretty_xml(tree, save_path)\n",
    "                print(f\"XML file created at: {save_path}\")\n",
    "                \n",
    "            return tree\n",
    "\n",
    "    def create_calibration_cfg(self, save_path=None, osimModelFile=None, leg='r'):\n",
    "\n",
    "        if leg not in ['r', 'l']:\n",
    "            raise ValueError(\"Leg must be 'r' or 'l'\")\n",
    "\n",
    "        \n",
    "                \n",
    "        dofs = [f\"hip_flexion_{leg}\", f\"knee_angle_{leg}\", f\"ankle_angle_{leg}\"]\n",
    "\n",
    "        # muscle_groups = [\n",
    "        #     f\"addbrev_{leg} addlong_{leg} addmagDist_{leg} addmagIsch_{leg} addmagMid_{leg} addmagProx_{leg} grac_{leg}\",\n",
    "        #     f\"bflh_{leg} semimem_{leg} semiten_{leg}\",\n",
    "        #     f\"bfsh_{leg}\",\n",
    "        #     f\"glmax1_{leg} glmax2_{leg} glmax3_{leg}\",\n",
    "        #     f\"glmed1_{leg} glmed2_{leg} glmed3_{leg}\",\n",
    "        #     f\"glmin1_{leg} glmin2_{leg} glmin3_{leg}\",\n",
    "        #     f\"sart_{leg} recfem_{leg} tfl_{leg}\",\n",
    "        #     f\"iliacus_{leg} psoas_{leg}\",\n",
    "        #     f\"perbrev_{leg} perlong_{leg} tibant_{leg} tibpost_{leg}\",\n",
    "        #     f\"edl_{leg} ehl_{leg} fdl_{leg} fhl_{leg}\",\n",
    "        #     f\"soleus_{leg} gaslat_{leg} gasmed_{leg}\",\n",
    "        #     f\"vasint_{leg} vaslat_{leg} vasmed_{leg}\",\n",
    "        #     f\"quad_fem_{leg} gem_{leg} peri_{leg} per_tert_{leg} ercspn_{leg} intobl_{leg} extobl_{leg}\"\n",
    "        # ]  \n",
    "    \n",
    "\n",
    "        root = ET.Element(\"calibration\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "        \n",
    "        algorithm = ET.SubElement(root, \"algorithm\")\n",
    "        simulated_annealing = ET.SubElement(algorithm, \"simulatedAnnealing\")\n",
    "        ET.SubElement(simulated_annealing, \"noEpsilon\").text = \"4\"\n",
    "        ET.SubElement(simulated_annealing, \"rt\").text = \"0.3\"\n",
    "        ET.SubElement(simulated_annealing, \"T\").text = \"200000\"\n",
    "        ET.SubElement(simulated_annealing, \"NS\").text = \"15\"\n",
    "        ET.SubElement(simulated_annealing, \"NT\").text = \"5\"\n",
    "        ET.SubElement(simulated_annealing, \"epsilon\").text = \"1.E-5\"\n",
    "        ET.SubElement(simulated_annealing, \"maxNoEval\").text = \"200000\"\n",
    "        \n",
    "        nms_model = ET.SubElement(root, \"NMSmodel\")\n",
    "        model_type = ET.SubElement(nms_model, \"type\")\n",
    "        ET.SubElement(model_type, \"openLoop\")\n",
    "        tendon = ET.SubElement(nms_model, \"tendon\")\n",
    "        ET.SubElement(tendon, \"equilibriumElastic\")\n",
    "        activation = ET.SubElement(nms_model, \"activation\")\n",
    "        ET.SubElement(activation, \"exponential\")\n",
    "        \n",
    "        calibration_steps = ET.SubElement(root, \"calibrationSteps\")\n",
    "        step = ET.SubElement(calibration_steps, \"step\")\n",
    "        ET.SubElement(step, \"dofs\").text = \" \".join(dofs)\n",
    "        \n",
    "        objective_function = ET.SubElement(step, \"objectiveFunction\")\n",
    "        torque_error_normalised = ET.SubElement(objective_function, \"torqueErrorNormalised\")\n",
    "        ET.SubElement(torque_error_normalised, \"targets\").text = \"all\"\n",
    "        ET.SubElement(torque_error_normalised, \"weight\").text = \"1\"\n",
    "        ET.SubElement(torque_error_normalised, \"exponent\").text = \"1\"\n",
    "        \n",
    "        penalty = ET.SubElement(objective_function, \"penalty\")\n",
    "        ET.SubElement(penalty, \"targets\").text = \"all\"\n",
    "        ET.SubElement(penalty, \"targetsType\").text = \"normalisedFibreLength\"\n",
    "        ET.SubElement(penalty, \"weight\").text = \"100\"\n",
    "        ET.SubElement(penalty, \"exponent\").text = \"2\"\n",
    "        ET.SubElement(penalty, \"range\").text = \"0.6 1.4\"\n",
    "        \n",
    "        parameter_set = ET.SubElement(step, \"parameterSet\")\n",
    "            \n",
    "        parameters = [\n",
    "            {\"name\": \"c1\", \"range\": \"-0.95 -0.05\"},\n",
    "            {\"name\": \"c2\", \"range\": \"-0.95 -0.05\"},\n",
    "            {\"name\": \"shapeFactor\", \"range\": \"-2.999 -0.001\"},\n",
    "            {\"name\": \"tendonSlackLength\", \"range\": \"0.85 1.15\", \"relative\": True},\n",
    "            {\"name\": \"optimalFibreLength\", \"range\": \"0.85 1.15\", \"relative\": True},\n",
    "            {\"name\": \"strengthCoefficient\", \"range\": \"0.8 2\"}\n",
    "        ]\n",
    "        \n",
    "        for param in parameters:\n",
    "            parameter = ET.SubElement(parameter_set, \"parameter\")\n",
    "            ET.SubElement(parameter, \"name\").text = param[\"name\"]\n",
    "            \n",
    "            # Check if this parameter has a muscle group\n",
    "            if \"muscleGroups\" in param:\n",
    "                muscle_groups = ET.SubElement(parameter, \"muscleGroups\")\n",
    "                for muscle in param[\"muscleGroups\"]:\n",
    "                    ET.SubElement(muscle_groups, \"muscles\").text = muscle\n",
    "            else:\n",
    "                # If no muscle group, assume it's a single muscle parameter\n",
    "                ET.SubElement(parameter, \"single\")\n",
    "\n",
    "\n",
    "            if \"relative\" in param and param[\"relative\"]:\n",
    "                relative = ET.SubElement(parameter, \"relativeToSubjectValue\")\n",
    "                ET.SubElement(relative, \"range\").text = param[\"range\"]\n",
    "            else:\n",
    "                absolute = ET.SubElement(parameter, \"absolute\")\n",
    "                ET.SubElement(absolute, \"range\").text = param[\"range\"]\n",
    "           \n",
    "        \n",
    "        ET.SubElement(root, \"trialSet\").text = \".\\\\trial.xml\"\n",
    "        \n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "        \n",
    "        return tree\n",
    "\n",
    "    def create_ceinms_trial_xml(self, savepath = None):\n",
    "        root = ET.Element(\"inputData\")\n",
    "\n",
    "        muscle_tendon_length_file = ET.SubElement(root, \"muscleTendonLengthFile\")\n",
    "        muscle_tendon_length_file.text = f\"../Results_SO_and_MA/MuscleAnalysis_Length.sto\"\n",
    "\n",
    "        excitations_file = ET.SubElement(root, \"excitationsFile\")\n",
    "        excitations_file.text = \"../processed_emg_signals.mot\"\n",
    "\n",
    "        moment_arms_files = ET.SubElement(root, \"momentArmsFiles\")\n",
    "        moment_arms_file_ankle_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"ankle_angle_l\")\n",
    "        moment_arms_file_ankle_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_ankle_angle_l.sto\"\n",
    "        moment_arms_file_ankle_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"ankle_angle_r\")\n",
    "        moment_arms_file_ankle_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_ankle_angle_r.sto\"\n",
    "        moment_arms_file_hip_adduction_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_adduction_l\")\n",
    "        moment_arms_file_hip_adduction_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_adduction_l.sto\"\n",
    "        moment_arms_file_hip_adduction_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_adduction_r\")\n",
    "        moment_arms_file_hip_adduction_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_adduction_r.sto\"\n",
    "        moment_arms_file_hip_flexion_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_flexion_l\")\n",
    "        moment_arms_file_hip_flexion_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_flexion_l.sto\"\n",
    "        moment_arms_file_hip_flexion_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_flexion_r\")\n",
    "        moment_arms_file_hip_flexion_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_flexion_r.sto\"\n",
    "        moment_arms_file_hip_rotation_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_rotation_l\")\n",
    "        moment_arms_file_hip_rotation_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_rotation_l.sto\"\n",
    "        moment_arms_file_hip_rotation_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_rotation_r\")\n",
    "        moment_arms_file_hip_rotation_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_rotation_r.sto\"\n",
    "        moment_arms_file_knee_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"knee_angle_l\")\n",
    "        moment_arms_file_knee_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_knee_angle_l.sto\"\n",
    "        moment_arms_file_knee_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"knee_angle_r\")\n",
    "        moment_arms_file_knee_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_knee_angle_r.sto\"\n",
    "\n",
    "        external_torques_file = ET.SubElement(root, \"externalTorquesFile\")\n",
    "        external_torques_file.text = \"../inverse_dynamics.sto\"\n",
    "\n",
    "        external_loads_file = ET.SubElement(root, \"externalLoadsFile\")\n",
    "        external_loads_file.text = \"../GRF_Setup.xml\"\n",
    "\n",
    "        motion_file = ET.SubElement(root, \"motionFile\")\n",
    "        motion_file.text = \"../Visual3d_SIMM_input.mot\"\n",
    "\n",
    "        start_stop_time = ET.SubElement(root, \"startStopTime\")\n",
    "\n",
    "        inverse_dynamics_file = os.path.join(self.path, 'inverse_dynamics.sto')\n",
    "        if os.path.isfile(inverse_dynamics_file):\n",
    "            with open(inverse_dynamics_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Find where the header ends\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.strip() == 'endheader':\n",
    "                    header_end_index = i\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Error: 'endheader' not found in file.\")\n",
    "                header_end_index = None\n",
    "\n",
    "            if header_end_index is not None:\n",
    "                # Read data into pandas\n",
    "                from io import StringIO\n",
    "                data_str = ''.join(lines[header_end_index + 1:])  # includes column names and data\n",
    "                df = pd.read_csv(StringIO(data_str), delim_whitespace=True)\n",
    "\n",
    "                if 'time' in df.columns:\n",
    "                    start_time = df['time'].iloc[0]\n",
    "                    end_time = df['time'].iloc[-1]\n",
    "                    start_stop_time.text = f\"{start_time} {end_time}\"\n",
    "                else:\n",
    "                    print(\"Error: 'time' column not found in inverse_dynamics.sto\")\n",
    "        else:\n",
    "            print(\"Error: File inverse_dynamics.sto not found\")\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        if savepath is not None:\n",
    "            save_pretty_xml(tree, savepath)\n",
    "            print(f\"XML file created at: {savepath}\")\n",
    "\n",
    "    def create_subject_uncalibrated(self, save_path=None, osimModelFile=None, leg='r'):\n",
    "        if osimModelFile == None:\n",
    "            print(\"\\033[93mNo OpenSim model not file provided. FAILED!!\\033[0m\")\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                model = osim.Model(osimModelFile)\n",
    "                coordinate_set = model.getCoordinateSet()\n",
    "                muscles = model.getMuscles() # ForceSet\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading OpenSim model: {e}\")\n",
    "                return None\n",
    "        \n",
    "        osim_model_file_name = os.path.basename(osimModelFile) \n",
    "        root = ET.Element(\"subject\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "        \n",
    "        mtu_default = ET.SubElement(root, \"mtuDefault\")\n",
    "        ET.SubElement(mtu_default, \"emDelay\").text = \"0.015\"\n",
    "        ET.SubElement(mtu_default, \"percentageChange\").text = \"0.15\"\n",
    "        ET.SubElement(mtu_default, \"damping\").text = \"0.1\"\n",
    "        \n",
    "        curves = [\n",
    "            {\n",
    "                \"name\": \"activeForceLength\",\n",
    "                \"xPoints\": \"-5 0 0.401 0.402 0.4035 0.52725 0.62875 0.71875 0.86125 1.045 1.2175 1.4387 1.6187 1.62 1.621 2.2 5\",\n",
    "                \"yPoints\": \"0 0 0 0 0 0.22667 0.63667 0.85667 0.95 0.99333 0.77 0.24667 0 0 0 0 0\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"passiveForceLength\",\n",
    "                \"xPoints\": \"-5 0.998 0.999 1 1.1 1.2 1.3 1.4 1.5 1.6 1.601 1.602 5\",\n",
    "                \"yPoints\": \"0 0 0 0 0.035 0.12 0.26 0.55 1.17 2 2 2 2\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"forceVelocity\",\n",
    "                \"xPoints\": \"-10 -1 -0.6 -0.3 -0.1 0 0.1 0.3 0.6 0.8 10\",\n",
    "                \"yPoints\": \"0 0 0.08 0.2 0.55 1 1.4 1.6 1.7 1.75 1.75\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"tendonForceStrain\",\n",
    "                \"xPoints\": \"0 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009 0.01 0.011 0.012 0.013 0.014 0.015 0.016 0.017 0.018 0.019 0.02 0.021 0.022 0.023 0.024 0.025 0.026 0.027 0.028 0.029 0.03 0.031 0.032 0.033 0.034 0.035 0.036 0.037 0.038 0.039 0.04 0.041 0.042 0.043 0.044 0.045 0.046 0.047 0.048 0.049 0.05 0.051 0.052 0.053 0.054 0.055 0.056 0.057 0.058 0.059 0.06 0.061 0.062 0.063 0.064 0.065 0.066 0.067 0.068 0.069 0.07 0.071 0.072 0.073 0.074 0.075 0.076 0.077 0.078 0.079 0.08 0.081 0.082 0.083 0.084 0.085 0.086 0.087 0.088 0.089 0.09 0.091 0.092 0.093 0.094 0.095 0.096 0.097 0.098 0.099 0.1\",\n",
    "                \"yPoints\": \"0 0.0012652 0.0073169 0.016319 0.026613 0.037604 0.049078 0.060973 0.073315 0.086183 0.099678 0.11386 0.12864 0.14386 0.15928 0.17477 0.19041 0.20658 0.22365 0.24179 0.26094 0.28089 0.30148 0.32254 0.34399 0.36576 0.38783 0.41019 0.43287 0.45591 0.4794 0.50344 0.52818 0.55376 0.58022 0.60747 0.63525 0.66327 0.69133 0.71939 0.74745 0.77551 0.80357 0.83163 0.85969 0.88776 0.91582 0.94388 0.97194 1 1.0281 1.0561 1.0842 1.1122 1.1403 1.1684 1.1964 1.2245 1.2526 1.2806 1.3087 1.3367 1.3648 1.3929 1.4209 1.449 1.477 1.5051 1.5332 1.5612 1.5893 1.6173 1.6454 1.6735 1.7015 1.7296 1.7577 1.7857 1.8138 1.8418 1.8699 1.898 1.926 1.9541 1.9821 2.0102 2.0383 2.0663 2.0944 2.1224 2.1505 2.1786 2.2066 2.2347 2.2628 2.2908 2.3189 2.3469 2.375 2.4031 2.4311\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for curve in curves:\n",
    "            curve_element = ET.SubElement(mtu_default, \"curve\")\n",
    "            ET.SubElement(curve_element, \"name\").text = curve[\"name\"]\n",
    "            ET.SubElement(curve_element, \"xPoints\").text = curve[\"xPoints\"]\n",
    "            ET.SubElement(curve_element, \"yPoints\").text = curve[\"yPoints\"]\n",
    "        \n",
    "        mtu_set = ET.SubElement(root, \"mtuSet\")\n",
    "        try:\n",
    "            mtus = []\n",
    "            for muscle in muscles:\n",
    "                if self.subject.startswith('PC'):\n",
    "                    ofl = muscle.getOptimalFiberLength() * 0.7  # Adjust for CP children Rabbi, M. F. et al. -2024- Biomech. Model. Mechanobiol. 23, 1077–1090\n",
    "                else:\n",
    "                    ofl = muscle.getOptimalFiberLength()\n",
    "\n",
    "                mtu = {\n",
    "                    \"name\": muscle.getName(),\n",
    "                    \"c1\": \"-0.5\",\n",
    "                    \"c2\": \"-0.5\",\n",
    "                    \"shapeFactor\": \"0.1\",\n",
    "                    \"optimalFibreLength\": str(ofl),\n",
    "                    \"pennationAngle\": str(muscle.getPennationAngleAtOptimalFiberLength()),\n",
    "                    \"tendonSlackLength\": str(muscle.getTendonSlackLength()),\n",
    "                    \"maxIsometricForce\": str(muscle.getMaxIsometricForce()),\n",
    "                    \"strengthCoefficient\": \"1\"\n",
    "                }\n",
    "                mtus.append(mtu)\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding OpenSim muscles: {e}\")\n",
    "            return None\n",
    "                        \n",
    "        for mtu in mtus:\n",
    "            mtu_element = ET.SubElement(mtu_set, \"mtu\")\n",
    "            ET.SubElement(mtu_element, \"name\").text = mtu[\"name\"]\n",
    "            ET.SubElement(mtu_element, \"c1\").text = mtu[\"c1\"]\n",
    "            ET.SubElement(mtu_element, \"c2\").text = mtu[\"c2\"]\n",
    "            ET.SubElement(mtu_element, \"shapeFactor\").text = mtu[\"shapeFactor\"]\n",
    "            ET.SubElement(mtu_element, \"optimalFibreLength\").text = mtu[\"optimalFibreLength\"]\n",
    "            ET.SubElement(mtu_element, \"pennationAngle\").text = mtu[\"pennationAngle\"]\n",
    "            ET.SubElement(mtu_element, \"tendonSlackLength\").text = mtu[\"tendonSlackLength\"]\n",
    "            ET.SubElement(mtu_element, \"maxIsometricForce\").text = mtu[\"maxIsometricForce\"]\n",
    "            ET.SubElement(mtu_element, \"strengthCoefficient\").text = mtu[\"strengthCoefficient\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        dof_set = ET.SubElement(root, \"dofSet\")\n",
    "\n",
    "        dofs = [\n",
    "                    {\"name\": f\"hip_adduction_{leg}\", \n",
    "                     \"mtuNameSet\": f\"add_brev_{leg} add_long_{leg} add_mag1_{leg} add_mag2_{leg} add_mag3_{leg} bifemlh_{leg} grac_{leg} pect_{leg} semimem_{leg} semiten_{leg} glut_max1_{leg} glut_med1_{leg} glut_med2_{leg} glut_med3_{leg} glut_min1_{leg} glut_min2_{leg} glut_min3_{leg} peri_{leg} sar_{leg} tfl_{leg}\"},\n",
    "                    {\"name\": f\"hip_rotation_{leg}\", \n",
    "                     \"mtuNameSet\": f\"glut_med1_{leg} glut_min1_{leg} iliacus_{leg} psoas_{leg} tfl_{leg} gem_{leg} glut_med3_{leg} glut_min3_{leg} peri_{leg} quad_fem_{leg}\"},\n",
    "                    {\"name\": f\"hip_flexion_{leg}\", \n",
    "                     \"mtuNameSet\": f\"add_brev_{leg} add_long_{leg} add_mag1_{leg} add_mag2_{leg} add_mag3_{leg} bifemlh_{leg} glut_max1_{leg} glut_max2_{leg} glut_max3_{leg} glut_med1_{leg} glut_med3_{leg} glut_min1_{leg} glut_min3_{leg} grac_{leg} iliacus_{leg} pect_{leg} psoas_{leg} rect_fem_{leg} sar_{leg} semimem_{leg} semiten_{leg} tfl_{leg} \"},\n",
    "                    {\"name\": f\"knee_angle_{leg}\", \n",
    "                     \"mtuNameSet\": f\"bifemlh_{leg} bifemsh_{leg} grac_{leg} lat_gas_{leg} med_gas_{leg} sar_{leg} semimem_{leg} semiten_{leg} rect_fem_{leg} vas_int_{leg} vas_lat_{leg} vas_med_{leg}\"},\n",
    "                    {\"name\": f\"ankle_angle_{leg}\", \n",
    "                     \"mtuNameSet\": f\"ext_dig_{leg} ext_hal_{leg} per_tert_{leg} tib_ant_{leg} flex_dig_{leg} flex_hal_{leg} lat_gas_{leg} med_gas_{leg} per_brev_{leg} per_long_{leg} soleus_{leg} tib_post_{leg}\"}\n",
    "                ]\n",
    "\n",
    "        for dof in dofs:\n",
    "            dof_element = ET.SubElement(dof_set, \"dof\")\n",
    "            ET.SubElement(dof_element, \"name\").text = dof[\"name\"]\n",
    "            ET.SubElement(dof_element, \"mtuNameSet\").text = dof[\"mtuNameSet\"]\n",
    "       \n",
    "        \n",
    "        calibration_info = ET.SubElement(root, \"calibrationInfo\")\n",
    "        uncalibrated = ET.SubElement(calibration_info, \"uncalibrated\")\n",
    "        ET.SubElement(uncalibrated, \"subjectID\").text = osim_model_file_name\n",
    "        ET.SubElement(uncalibrated, \"additionalInfo\").text = \"TendonSlackLength and OptimalFibreLength scaled with Winby-Modenese\"\n",
    "        \n",
    "        ET.SubElement(root, \"opensimModelFile\").text = \"..\\\\..\\\\\" + osim_model_file_name\n",
    "        \n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "        \n",
    "        return tree\n",
    "\n",
    "    def create_excitation_generator(self, save_path=None, leg='r', input_signals=None):\n",
    "        if leg not in ['l', 'r']:\n",
    "            raise ValueError(\"Leg must be 'l' or 'r'\")\n",
    "\n",
    "        # Define the input signals and excitations\n",
    "        input_signals = ['GLTMED', 'RF', 'ADDLONG', 'ST', 'TA', 'GM']\n",
    "        excitations = [\n",
    "            'add_brev', 'add_long', 'bifemlh', 'bifemsh', 'ext_dig', 'ext_hal', \n",
    "            'flex_dig', 'flex_hal', 'lat_gas', 'med_gas', 'glut_max1', 'glut_max2', \n",
    "            'glut_max3', 'glut_med1', 'glut_med2', 'glut_med3', 'glut_min1', \n",
    "            'glut_min2', 'glut_min3', 'grac', 'iliacus', 'per_brev', 'per_long', \n",
    "            'psoas', 'rect_fem', 'sar', 'semimem', 'semiten', 'soleus', 'tfl', \n",
    "            'tib_ant', 'tib_post', 'vas_int', 'vas_lat', 'vas_med', 'add_mag1', \n",
    "            'add_mag2', 'add_mag3', 'pect', 'quad_fem', 'gem', 'peri', 'per_tert', \n",
    "            'ercspn', 'intobl', 'extobl'\n",
    "        ]\n",
    "        # Define the correct mapping of muscles to EMG signals\n",
    "        muscle_to_signal = {\n",
    "            \"add_brev\": \"ADDLONG\",\n",
    "            \"add_long\": \"ADDLONG\",\n",
    "            \"grac\": \"ADDLONG\",\n",
    "            \"bifemlh\": \"ST\",\n",
    "            \"bifemsh\": \"ST\",\n",
    "            \"semimem\": \"ST\",\n",
    "            \"semiten\": \"ST\",\n",
    "            \"ext_dig\": \"TA\",\n",
    "            \"ext_hal\": \"TA\",\n",
    "            \"tib_ant\": \"TA\",\n",
    "            \"lat_gas\": \"GM\",\n",
    "            \"med_gas\": \"GM\",\n",
    "            \"soleus\": \"GM\",\n",
    "            \"glut_max1\": \"GLTMED\",\n",
    "            \"glut_max2\": \"GLTMED\",\n",
    "            \"glut_max3\": \"GLTMED\",\n",
    "            \"glut_med1\": \"GLTMED\",\n",
    "            \"glut_med2\": \"GLTMED\",\n",
    "            \"glut_med3\": \"GLTMED\",\n",
    "            \"glut_min1\": \"GLTMED\",\n",
    "            \"glut_min2\": \"GLTMED\",\n",
    "            \"glut_min3\": \"GLTMED\",\n",
    "            \"rect_fem\": \"RF\",\n",
    "        }\n",
    "        # Create the root element\n",
    "        root = ET.Element('excitationGenerator', {\n",
    "            'xmlns:xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n",
    "            'xsi:noNamespaceSchemaLocation': 'excitationGenerator.xsd'\n",
    "        })\n",
    "\n",
    "        # Create the inputSignals element (Only include signals for the selected leg)\n",
    "        input_signals_element = ET.SubElement(root, 'inputSignals', {'type': 'EMG'})\n",
    "        input_signals_element.text = ' '.join([f'{leg.upper()}{signal}' for signal in input_signals])\n",
    "\n",
    "        # Create the mapping element\n",
    "        mapping_element = ET.SubElement(root, 'mapping')\n",
    "\n",
    "        # Add excitations to the mapping element\n",
    "        for excitation in excitations:\n",
    "            excitation_element = ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_{leg}'})\n",
    "            if excitation in muscle_to_signal:\n",
    "                input_element = ET.SubElement(excitation_element, 'input')\n",
    "                input_element.set('weight', '1')\n",
    "                input_element.text = f\"{leg.upper()}{muscle_to_signal[excitation]}\"\n",
    "\n",
    "        # Add left leg muscles without assigning any input\n",
    "        if leg == 'r':\n",
    "            for excitation in excitations:\n",
    "                ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_l'})\n",
    "        elif leg == 'l':\n",
    "            for excitation in excitations:\n",
    "                ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_r'})\n",
    "\n",
    "        # Create the tree and write to file\n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:    \n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "\n",
    "    def create_execution_setup(self, save_path=None):\n",
    "        root = ET.Element(\"ceinms\")\n",
    "\n",
    "        subject_file = ET.SubElement(root, \"subjectFile\")\n",
    "        subject_file.text = \".\\\\calibratedSubject.xml\"\n",
    "\n",
    "        input_data_file = ET.SubElement(root, \"inputDataFile\")\n",
    "        input_data_file.text = \".\\\\trial.xml\"\n",
    "\n",
    "        execution_file = ET.SubElement(root, \"executionFile\")\n",
    "        execution_file.text = \".\\\\executionCfg.xml\"\n",
    "\n",
    "        excitation_generator_file = ET.SubElement(root, \"excitationGeneratorFile\")\n",
    "        excitation_generator_file.text = \".\\\\excitationGenerator.xml\"\n",
    "\n",
    "        output_directory = ET.SubElement(root, \"outputDirectory\")\n",
    "        output_directory.text = \".\\\\execution\"\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"Execution setup file created at: {save_path}\")\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def create_execution_cfg(self,save_path=None,leg='r'):\n",
    "        root = ET.Element(\"execution\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "\n",
    "        nms_model = ET.SubElement(root, \"NMSmodel\")\n",
    "        model_type = ET.SubElement(nms_model, \"type\")\n",
    "        hybrid = ET.SubElement(model_type, \"hybrid\")\n",
    "\n",
    "        ET.SubElement(hybrid, \"alpha\").text = \"1\"\n",
    "        ET.SubElement(hybrid, \"beta\").text = \"5\"\n",
    "        ET.SubElement(hybrid, \"gamma\").text = \"10\"\n",
    "        ET.SubElement(hybrid, \"dofSet\").text = \" \".join([f\"hip_flexion_{leg}\", f\"knee_angle_{leg}\", f\"ankle_angle_{leg}\"])\n",
    "        ET.SubElement(hybrid, \"synthMTUs\").text = f\"flex_dig_{leg} flex_hal_{leg} iliacus_{leg} per_brev_{leg} per_long_{leg} psoas_{leg} sar_{leg} tfl_{leg} tib_post_{leg} add_mag1_{leg} add_mag2_{leg} add_mag3_{leg} quad_fem_{leg} gem_{leg} peri_{leg} per_tert_{leg} ercspn_{leg} intobl_{leg} extobl_{leg} pect_{leg} vas_int_{leg} vas_lat_{leg} vas_med_{leg}\"\n",
    "        ET.SubElement(hybrid, \"adjustMTUs\").text = f\"add_brev_{leg} add_long_{leg} bifemlh_{leg} bifemsh_{leg} ext_dig_{leg} ext_hal_{leg} lat_gas_{leg} med_gas_{leg} glut_max1_{leg} glut_max2_{leg} glut_max3_{leg} glut_med1_{leg} glut_med2_{leg} glut_med3_{leg} glut_min1_{leg} glut_min2_{leg} glut_min3_{leg} grac_{leg} semimem_{leg} semiten_{leg} soleus_{leg} tib_ant_{leg}  rect_fem_{leg}\"\n",
    "\n",
    "        algorithm = ET.SubElement(hybrid, \"algorithm\")\n",
    "        simulated_annealing = ET.SubElement(algorithm, \"simulatedAnnealing\")\n",
    "        ET.SubElement(simulated_annealing, \"noEpsilon\").text = \"4\"\n",
    "        ET.SubElement(simulated_annealing, \"rt\").text = \"0.3\"\n",
    "        ET.SubElement(simulated_annealing, \"T\").text = \"20000\"\n",
    "        ET.SubElement(simulated_annealing, \"NS\").text = \"15\"\n",
    "        ET.SubElement(simulated_annealing, \"NT\").text = \"5\"\n",
    "        ET.SubElement(simulated_annealing, \"epsilon\").text = \"0.001\"\n",
    "        ET.SubElement(simulated_annealing, \"maxNoEval\").text = \"200000\"\n",
    "\n",
    "        tendon = ET.SubElement(nms_model, \"tendon\")\n",
    "        equilibrium_elastic = ET.SubElement(tendon, \"equilibriumElastic\")\n",
    "        ET.SubElement(equilibrium_elastic, \"tolerance\").text = \"1e-09\"\n",
    "\n",
    "        activation = ET.SubElement(nms_model, \"activation\")\n",
    "        ET.SubElement(activation, \"exponential\")\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"Execution configuration file created at: {save_path}\")\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def create_ceinms_files(self, osim_model_path = None, leg=None, input_signals = None):\n",
    "        \n",
    "        if not osim_model_path:\n",
    "            print(\"No OpenSim model file provided.\")\n",
    "            return\n",
    "        \n",
    "        if not input_signals:\n",
    "            print(\"No input signals provided.\")\n",
    "            return\n",
    "\n",
    "        if not leg:\n",
    "            print(\"No leg provided.\")\n",
    "            return\n",
    "        \n",
    "        # Calibration Setup\n",
    "        # savepath = self.ceinms_cal_setup.path\n",
    "        # self.create_calibration_setup(savepath)\n",
    "\n",
    "        # # Calibration Configuration\n",
    "        savepath = self.ceinms_cal_cfg.path\n",
    "        self.create_calibration_cfg(savepath, osimModelFile=osim_model_path,leg=leg)\n",
    "\n",
    "        # # Trial\n",
    "        # savepath = self.ceinms_trial.path\n",
    "        # self.create_ceinms_trial_xml(savepath)\n",
    "\n",
    "        # Uncalibrated Model \n",
    "        # savepath = self.ceinms_uncalibrated_subject.path\n",
    "        # self.create_subject_uncalibrated(save_path=savepath,osimModelFile=osim_model_path, leg=leg)\n",
    "\n",
    "        # Excitation Generator\n",
    "        # savepath = self.ceinms_excitation_generator.path\n",
    "        # self.create_excitation_generator(save_path=savepath, leg=leg, input_signals=input_signals)\n",
    "\n",
    "        # Execution Setup\n",
    "        # savepath = self.ceinms_execution_setup.path\n",
    "        # self.create_execution_setup(save_path=savepath)\n",
    "\n",
    "        # Execution Configuration\n",
    "        # savepath = self.ceinms_execution_cfg.path\n",
    "        # self.create_execution_cfg(save_path=savepath,leg=leg)\n",
    "\n",
    "class openSim:\n",
    "    def __init__(self, legs = ['r', 'l'], subjects =['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026'], trials_to_load = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3'], trial_number = 1):\n",
    "        try:\n",
    "            self.code_path = os.path.dirname(__file__)\n",
    "        except:\n",
    "            self.code_path = os.getcwd()\n",
    "        \n",
    "        self.simulations_path = os.path.join(os.path.dirname(self.code_path), 'Simulations')\n",
    "        self.subjects = {}\n",
    "        \n",
    "        for subject in subjects:\n",
    "            self.subjects[subject] = {}\n",
    "            self.subjects[subject]['model'] = os.path.join(self.simulations_path, subject, subject + '_scaled.osim')\n",
    "            for leg in legs: \n",
    "                for trial in trials_to_load:            \n",
    "                    self.trial_path = os.path.join(self.simulations_path, subject, f'{trial}_{leg}{trial_number}')\n",
    "                    try:\n",
    "                        trial = Trial(self.trial_path)\n",
    "                        self.subjects[subject][trial.name] = trial \n",
    "                    except Exception as e:\n",
    "                        self.subjects[subject][trial] =  None\n",
    "                        # print(f\"Error loading trial: {self.trial_path}\")\n",
    "                        # print(e)\n",
    "            \n",
    "        \n",
    "        self.ik_columns = [\"hip_flexion_leg\", \"hip_adduction_leg\", \"hip_rotation_leg\", \"knee_angle_leg\", \"ankle_angle_leg\"]\n",
    "        self.id_columns = [\"hip_flexion_leg\" + \"_moment\", \"hip_adduction_leg\" + \"_moment\", \"hip_rotation_leg\" + \"_moment\", \"knee_angle_leg\" + \"_moment\", \"ankle_angle_leg\" + \"_moment\"]\n",
    "        self.force_columns = [\"add_long_leg\", \"rect_fem_leg\", \"med_gas_leg\", \"semiten_leg\",\"tib_ant_leg\"]\n",
    "\n",
    "\n",
    "        self.titles = [\"Hip Flexion\", \"Hip Adduction\", \"Hip Rotation\", \"Knee Flexion\", \"Ankle Plantarflexion\"]\n",
    "        self.titles_muscles = [\"Adductor Longus\", \"Rectus Femoris\", \"Medial Gastrocnemius\", \"Semitendinosus\", \"Tibialis Anterior\"]\n",
    "\n",
    "    # Time Normalisation Function \n",
    "    def time_normalised_df(self, df, fs=None):\n",
    "        if not isinstance(df, msk.pd.DataFrame):\n",
    "            raise Exception('Input must be a pandas DataFrame')\n",
    "        \n",
    "        if not fs:\n",
    "            try:\n",
    "                fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "            except KeyError:\n",
    "                raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "            \n",
    "        normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        for column in df.columns:\n",
    "            if column == 'time':  # Skip time column\n",
    "                continue\t\n",
    "            normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "            currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "            timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "            Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "            normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "        return normalised_df\n",
    "\n",
    "    def plot_single_trial(self, show = False):\n",
    "        #Read .mot files\n",
    "        with open(self.mot_file, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the line where actual data starts (usually after 'endheader')\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"endheader\" in line:\n",
    "                start_row = i + 1  # Data starts after this line\n",
    "                break\n",
    "        else:\n",
    "            start_row = 0  # If 'endheader' is not found, assume no header\n",
    "\n",
    "        # Load data using Pandas\n",
    "        self.df_ik = msk.pd.read_csv(self.mot_file, delim_whitespace=True, start_row=start_row)\n",
    "        self.df_id = msk.pd.read_csv(self.id_file, sep=\"\\t\", start_row=6)\n",
    "        self.df_force = msk.pd.read_csv(self.force_file, sep=\"\\t\", start_row=14)\n",
    "\n",
    "        # Apply normalisation to both IK (angles) and ID (moments) data\n",
    "        self.df_ik_normalised = self.time_normalised_df(df=self.df_ik)\n",
    "        self.df_id_normalised = self.time_normalised_df(df=self.df_id)\n",
    "        self.df_force_normalised = self.time_normalised_df(df=self.df_force)\n",
    "\n",
    "        # Ensure time is normalised to 101 points\n",
    "        time_normalised = msk.np.linspace(0, 100, 101)  \n",
    " \n",
    "        # select the specified columns         \n",
    "        self.ik_data = self.df_ik_normalised[self.ik_columns]\n",
    "        self.id_data = self.df_id_normalised[self.id_columns]\n",
    "        self.force_data = self.df_force_normalised[self.force_columns]\n",
    "            \n",
    "        # Define the layout \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(15, 4)) \n",
    "\n",
    "        #Plot IK (angles)\n",
    "        for i, col in enumerate(self.ik_columns):\n",
    "            ax = axes[0,i]\n",
    "            ax.plot(time_normalised, self.ik_data[col], color='red')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Angle (deg)\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        #Plot ID (moments)\n",
    "        for i, col in enumerate(self.id_columns):\n",
    "            ax = axes[1,i]\n",
    "            ax.plot(time_normalised, self.id_data[col], color='blue')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Moment (Nm)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        # PLOT MUSCLE FORCES \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 4), sharex=True)\n",
    "\n",
    "        for i, col in enumerate(self.force_columns):\n",
    "            ax = axes[i]\n",
    "            ax.plot(time_normalised, self.force_data[col], color='green')\n",
    "            ax.set_title(self.titles_muscles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Force (N)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_multiple_trials(self, show=False):\n",
    "        self.df_ik_list = []  # Store loaded DataFrames\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "            for trial in self.subjects[subject]:\n",
    "                trial_obj = self.subjects[subject][trial]\n",
    "                if trial_obj:\n",
    "                    self.df_ik_list.append(trial_obj.ik.data)\n",
    "                    \n",
    "        for file in self.mot_files:  # Loop through each file\n",
    "            with open(file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Load data using Pandas\n",
    "            df = msk.pd.read_csv(file, delim_whitespace=True, skiprows=5)\n",
    "            self.df_ik_list.append(df)\n",
    "\n",
    "        # Normalize all loaded IK data\n",
    "        self.df_ik_normalised_list = []  # Store normalised DataFrames\n",
    "\n",
    "        for df in self.df_ik_list:  # Loop through each loaded DataFrame\n",
    "            df_normalised = self.time_normalised_df(df=df)  # Apply normalization\n",
    "            self.df_ik_normalised_list.append(df_normalised)  # Store normalised DataFrame\n",
    "\n",
    "        # Ensure time is normalised to 101 points\n",
    "        time_normalised = msk.np.linspace(0, 100, 101)\n",
    "\n",
    "        # Select the specified columns from normalised data\n",
    "        self.ik_data_list = []  # Store DataFrames with only the required columns\n",
    "\n",
    "        for df_normalised in self.df_ik_normalised_list:  # Loop through each normalised DataFrame\n",
    "            if set(self.ik_columns).issubset(df_normalised.columns):  # Check if columns exist\n",
    "                self.ik_data_list.append(df_normalised[self.ik_columns])  # Select only specified columns\n",
    "            else:\n",
    "                print(\"Warning: Some specified columns are missing in a file.\")\n",
    "\n",
    "        # Plot mean and sd\n",
    "        # Check if IK data exists\n",
    "        if not self.ik_data_list:\n",
    "            print(\"No IK data available to plot!\")\n",
    "        else:\n",
    "            # Convert list of DataFrames to a single NumPy array\n",
    "            combined_df = np.array([df.values for df in self.ik_data_list])  # Shape: (num_trials, num_timepoints, num_columns)\n",
    "\n",
    "            # Check if data is properly structured\n",
    "            if combined_df.shape[0] < 2:\n",
    "                print(\"Not enough trials to calculate mean and standard deviation!\")\n",
    "            else:\n",
    "                # Compute Mean and Standard Deviation\n",
    "                mean_values = np.mean(combined_df, axis=0)\n",
    "                std_values = np.std(combined_df, axis=0)\n",
    "\n",
    "                # Normalize time from 0 to 100% Gait Cycle\n",
    "                time_values = np.linspace(0, 100, combined_df.shape[1])\n",
    "\n",
    "                # Create a shared figure for all subplots\n",
    "                fig, axes = plt.subplots(nrows=1, ncols=len(self.ik_columns), figsize=(20, 5), sharex=True)\n",
    "\n",
    "                if len(self.ik_columns) == 1:\n",
    "                    axes = [axes]  # If only one column, ensure it's iterable\n",
    "\n",
    "                for i, col in enumerate(self.ik_columns):\n",
    "                    ax = axes[i]\n",
    "\n",
    "                    # Plot mean line\n",
    "                    ax.plot(time_values, mean_values[:, i], color='red', label=\"Mean\", linewidth=2)\n",
    "\n",
    "                    # Shade the standard deviation range\n",
    "                    ax.fill_between(time_values, mean_values[:, i] - std_values[:, i],\n",
    "                                    mean_values[:, i] + std_values[:, i], color='red', alpha=0.2, label=\"SD Range\")\n",
    "\n",
    "                    # Formatting\n",
    "                    ax.set_title(col)\n",
    "                    ax.set_xlabel(\"Gait Cycle (%)\")\n",
    "                    ax.set_xlim(0, 100)  # X-axis from 0% to 100% of the gait cycle\n",
    "                    ax.grid(True)\n",
    "\n",
    "                    # Set Y-label only for the first subplot\n",
    "                    if i == 0:\n",
    "                        ax.set_ylabel(\"Angle (Degrees)\")\n",
    "                        ax.legend()\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                if show:\n",
    "                    plt.show()\n",
    "\n",
    "def export_c3d(c3dFilePath):\n",
    "    analog_file_path = os.path.join(os.path.dirname(c3dFilePath),'analog.csv')\n",
    "    \n",
    "    # if the file already exists, return the file\n",
    "    if os.path.isfile(analog_file_path):\n",
    "        df = msk.pd.read_csv(analog_file_path)\n",
    "        return df\n",
    "    \n",
    "    print('Exporting analog data to csv ...')\n",
    "    \n",
    "    # read c3d file\n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    first_frame = reader.first_frame\n",
    "    num_frames = reader.frame_count\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    initial_time = first_frame / fs\n",
    "    final_time = (first_frame + num_frames-1) / fs\n",
    "    time = np.arange(first_frame / fs, final_time, 1 / fs) \n",
    "\n",
    "    df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "    df['time'] = time\n",
    "    \n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]    \n",
    "    \n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # convert analog data to list\n",
    "        analog_list  = analog.data.tolist()\n",
    "        \n",
    "        # loop through analog channels and add to dataframe\n",
    "        for i_channel in range(len(analog_list)):\n",
    "            channel_name = analog_labels[i_channel]\n",
    "            \n",
    "            # add channel to dataframe\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # save emg data to csv   \n",
    "    df.to_csv(analog_file_path)\n",
    "    print('analog.csv exported to ' + analog_file_path)  \n",
    "    \n",
    "    return df\n",
    "\n",
    "def export_analog(c3dFilePath=None, columns_to_mot='all'):\n",
    "    if not c3dFilePath:\n",
    "        print('C3D file path not provided')\n",
    "        return\n",
    "    \n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "    \n",
    "    # remove those not in columns_to_mot (fix: use column names to filter and get indices)\n",
    "    if columns_to_mot != 'all':\n",
    "        indices = [i for i, label in enumerate(analog_labels) if label in columns_to_mot]\n",
    "        analog_labels = [analog_labels[i] for i in indices]\n",
    "    else:\n",
    "        indices = list(range(len(analog_labels)))\n",
    "        columns_to_mot = analog_labels\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    marker_fs = reader.point_rate  # This is the actual frame rate for kinematics\n",
    "   \n",
    "\n",
    "    first_time = reader.first_frame / marker_fs\n",
    "    final_time = (reader.first_frame + reader.frame_count - 1) / marker_fs\n",
    "    time = msk.np.arange(first_time, final_time + 1 / marker_fs, 1 / marker_fs)\n",
    "  \n",
    "    num_frames = len(time)\n",
    "    df = msk.pd.DataFrame(index=range(num_frames), columns=analog_labels)\n",
    "    df['time'] = time\n",
    "\n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols] \n",
    "\n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # loop through selected analog channels and add to dataframe (fix: iterate over filtered indices)\n",
    "        for idx, i_channel in enumerate(indices):\n",
    "            channel_name = analog_labels[idx]\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # remove rows with NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # save emg data to csv\n",
    "    analog_csv_path = c3dFilePath.replace('.c3d', '_analog.csv')\n",
    "    df.to_csv(analog_csv_path, index=False)\n",
    "    \n",
    "    # save to mot\n",
    "    # self.csv_to_mot()\n",
    "    \n",
    "    return analog_csv_path\n",
    "\n",
    "def header_mot(df,name):\n",
    "\n",
    "        num_rows = len(df)\n",
    "        num_cols = len(df.columns) \n",
    "        inital_time = df['time'].iloc[0]\n",
    "        final_time = df['time'].iloc[-1]\n",
    "        df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "        return f'name {name}\\nnRows={num_rows}\\nnColumns={num_cols}\\n \\nendheader'\n",
    "\n",
    "def csv_to_mot(emg_csv, columns = 'all'):\n",
    "    \n",
    "    emg_data = msk.bops.pd.read_csv(emg_csv)\n",
    "    \n",
    "    try:\n",
    "        time = emg_data['time']\n",
    "    except:\n",
    "        time = emg_data['Time']\n",
    "\n",
    "    # start time from new time point\n",
    "    start_time = time.iloc[0]\n",
    "    end_time = time.iloc[-1]\n",
    "\n",
    "    num_samples = len(emg_data)\n",
    "    new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "    # remove columns not in columns_to_mot\n",
    "    if columns != 'all':\n",
    "        emg_data = emg_data[columns]\n",
    "\n",
    "    emg_data['time'] = new_time\n",
    "    # Ensure 'time' column is the first column\n",
    "    cols = emg_data.columns.tolist()\n",
    "    cols.insert(0, cols.pop(cols.index('time')))\n",
    "    emg_data = emg_data[cols]\n",
    "\n",
    "    # Define a new file path \n",
    "    new_file_path = os.path.join(emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "    # Save the modified DataFrame\n",
    "    emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "    # save to mot\n",
    "    header = header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "    mot_path = new_file_path.replace('.csv','.mot')\n",
    "    with open(mot_path, 'w') as f:\n",
    "        f.write(header + '\\n')  \n",
    "        # print column names \n",
    "        f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "        for index, row in emg_data.iterrows():\n",
    "            f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "    \n",
    "    print(f\"File saved: {mot_path}\")\n",
    "    \n",
    "    return mot_path\n",
    "\n",
    "def time_normalised_df(df, fs=None):\n",
    "    if not isinstance(df, msk.pd.DataFrame):\n",
    "        raise Exception('Input must be a pandas DataFrame')\n",
    "    \n",
    "    if not fs:\n",
    "        try:\n",
    "            fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "        except KeyError:\n",
    "            raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "        \n",
    "    normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for column in df.columns:\n",
    "        normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "        currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "        timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "        Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "        normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "    return normalised_df\n",
    "\n",
    "def save_pretty_xml(tree, save_path):\n",
    "            \"\"\"Saves the XML tree to a file with proper indentation.\"\"\"\n",
    "            # Convert to string and format with proper indents\n",
    "            rough_string = ET.tostring(tree.getroot(), 'utf-8')\n",
    "            reparsed = xml.dom.minidom.parseString(rough_string)\n",
    "            pretty_xml = reparsed.toprettyxml(indent=\"   \")\n",
    "\n",
    "            # Write to file\n",
    "            with open(save_path, 'w') as file:\n",
    "                file.write(pretty_xml)\n",
    "\n",
    "def filter_emg(signal, sample_rate=1000, low_pass_cutoff=6):\n",
    "    \"\"\"\n",
    "    Processes EMG signal: clean, rectify, and filter to get the envelope.\n",
    "    \"\"\"\n",
    "    cleaned_signal = nk.emg_clean(signal, sampling_rate=sample_rate, method='biosppy')\n",
    "    rectified_signal = np.abs(cleaned_signal)\n",
    "    low_pass = low_pass_cutoff / (sample_rate / 2)\n",
    "    b, a = sig.butter(4, low_pass, btype='lowpass')\n",
    "    emg_envelope = np.abs(sig.filtfilt(b, a, rectified_signal))\n",
    "\n",
    "    return emg_envelope\n",
    "\n",
    "def filter_emg_signals(csv_file, muscles, sample_rate=1000):\n",
    "    df = msk.pd.read_csv(csv_file)\n",
    "    filtered_data = {'time': df['time']}  # Add time column\n",
    "    \n",
    "    for muscle in muscles:\n",
    "        if muscle in df.columns:\n",
    "            filtered_data[muscle] = filter_emg(df[muscle].values, sample_rate)\n",
    "    \n",
    "    df_filtered = msk.pd.DataFrame(filtered_data)\n",
    "    \n",
    "    filtered_emg_path = csv_file.replace('.csv', '_filtered_emg.csv')\n",
    "    df_filtered.to_csv(filtered_emg_path, index=False)\n",
    "    \n",
    "    return filtered_emg_path\n",
    "\n",
    "def amplitude_normalise(processed_emg_path):\n",
    "    emg_data = pd.read_csv(processed_emg_path)\n",
    "    \n",
    "    # Separate time and signal\n",
    "    time = emg_data['time']\n",
    "    signal_data = emg_data.drop(columns=['time'])\n",
    "    \n",
    "    # Avoid divide-by-zero errors\n",
    "    max_vals = signal_data.max()\n",
    "    max_vals[max_vals == 0] = 1  # prevent division by zero\n",
    "\n",
    "    # Normalise each EMG signal\n",
    "    signal_normalised = signal_data / max_vals\n",
    "\n",
    "    # Combine back with time\n",
    "    emg_data_normalised = pd.concat([time, signal_normalised], axis=1)\n",
    "\n",
    "    # Save the result\n",
    "    normalised_emg_path = processed_emg_path.replace('.csv', '_normalised.csv')\n",
    "    emg_data_normalised.to_csv(normalised_emg_path, index=False)\n",
    "    \n",
    "    return normalised_emg_path\n",
    "\n",
    "def filter_force(signal, sample_rate=1000, low_pass_cutoff=20):\n",
    "    \"\"\"\n",
    "    Processes EMG signal: clean, rectify, and filter to get the envelope.\n",
    "    \"\"\"\n",
    "    return nk.signal_filter(signal, sampling_rate=sample_rate, highcut=low_pass_cutoff, method='butter')\n",
    "\n",
    "def normalize_time_act(df, start_time, duration):\n",
    "    df_norm = df.copy()\n",
    "    df_norm['time'] = 100 * (df_norm['time'] - start_time) / duration\n",
    "    return df_norm  \n",
    "\n",
    "def find_file_endheader_line(path):\n",
    "        with open(path, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if 'endheader' in line:\n",
    "                    return i + 1\n",
    "        return 0  \n",
    "\n",
    "def import_file(path):\n",
    "    \n",
    "    endline = find_file_endheader_line(path)\n",
    "    data = pd.read_csv(path, skiprows=endline, sep='\\t')\n",
    "    return data\n",
    "\n",
    "def rmse_calc(y_true,y_predict):\n",
    "    return np.sqrt(np.mean((y_true - y_predict) ** 2))\n",
    "\n",
    "def compute_rmse_r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute RMSE and R² between two 1D arrays (or Series).\n",
    "    Assumes the arrays have the same length.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    rmse = rmse_calc(y_true, y_pred)\n",
    "    \n",
    "   \n",
    "    #r2 = r2_score(y_true, y_pred) # from sklearn.metrics\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(y_true, y_pred)\n",
    "    r2 = r_value ** 2 # Bas's formula\n",
    "\n",
    "    # r, _ = pearsonr(y_true, y_pred)\n",
    "    # r2 = r**2\n",
    "    \n",
    "    return rmse, r2\n",
    "\n",
    "def resample_curve(x, y, target_length):\n",
    "    \"\"\"\n",
    "    Resample curve (x and y) to have target_length samples using linear interpolation.\n",
    "    x is assumed to be 1D (e.g., a pandas Series).\n",
    "    \"\"\"\n",
    "    # Create a new time grid between x.min() and x.max()\n",
    "    new_x = np.linspace(x.iloc[0], x.iloc[-1], target_length)\n",
    "    new_y = np.interp(new_x, x, y)\n",
    "    return new_x, new_y\n",
    "\n",
    "def crop_time(df, start_time, end_time):\n",
    "    \"\"\"Crop DataFrame rows to data between start_time and end_time.\"\"\"\n",
    "    return df[(df['time'] >= start_time) & (df['time'] <= end_time)].reset_index(drop=True)\n",
    "\n",
    "def normalize_time(df, start_time, duration):\n",
    "    \"\"\"\n",
    "    Normalize the 'time' column to a percentage scale (0-100) using given start_time and duration.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['time'] = 100 * (df['time'] - start_time) / duration\n",
    "    return df\n",
    "\n",
    "def load_sto(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    start_idx = next(i for i, line in enumerate(lines) if 'endheader' in line.lower()) + 1\n",
    "    return pd.read_csv(StringIO(''.join(lines[start_idx:])), delim_whitespace=True)\n",
    "\n",
    "def load_mot(fp):\n",
    "    txt = fp.read_text().splitlines()\n",
    "    idx = next(i for i,l in enumerate(txt) if 'endheader' in l.lower())+1\n",
    "    return pd.read_csv(StringIO(\"\\n\".join(txt[idx:])), delim_whitespace=True)\n",
    "\n",
    "def resample_to_percent_phase(df, target_len=101):\n",
    "\n",
    "    n = df.shape[0]\n",
    "    old_x = np.linspace(0, 100, n)\n",
    "    new_x = np.linspace(0, 100, target_len)\n",
    "    return pd.DataFrame({\n",
    "        col: interp1d(old_x, df[col].values, kind='linear')(new_x)\n",
    "        for col in df.columns\n",
    "    })\n",
    "\n",
    "def gather_data(subjects, trials, groups_map):\n",
    "    \"\"\" Return dict: subject -> list of {group: df_resampled} \"\"\"\n",
    "    data = {s: [] for s in subjects}\n",
    "    for s in subjects:\n",
    "        for tr in trials:\n",
    "            fp = simulations_dir/s/tr/'ceinms'/'execution'/'MuscleForces.sto'\n",
    "            if not fp.exists(): continue\n",
    "            df = load_sto(fp)\n",
    "            d = {}\n",
    "            for grp, cols in groups_map.items():\n",
    "                valid = [m for m in cols if m in df.columns]\n",
    "                if valid:\n",
    "                    d[grp] = resample_to_percent_phase(df[valid])\n",
    "            if d:\n",
    "                data[s].append(d)\n",
    "    return data\n",
    "\n",
    "def fix_time_scale(df, expected_inc=0.01, factor=10):\n",
    "    dt = df['time'].diff().median()\n",
    "    if dt < expected_inc * 0.5:\n",
    "        df2 = df.copy()\n",
    "        df2['time'] *= factor\n",
    "        return df2\n",
    "    return df\n",
    "\n",
    "def compute_so_joint_moments(so_force, moment_arms, joint_suffix):\n",
    "    out = {'time': so_force['time']}\n",
    "    for j, suf in joint_suffix.items():\n",
    "        so_col = suf['so']\n",
    "        ma_df = moment_arms.get(so_col)\n",
    "        if ma_df is None:\n",
    "            continue\n",
    "        muscles = [m for m in ma_df.columns if m!='time' and m in so_force.columns]\n",
    "        moment = sum(so_force[m]*ma_df[m] for m in muscles)\n",
    "        out[so_col] = moment.values\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "def compute_rmse_r2_drop(y_true, y_pred, drop_initial=3):\n",
    "    \"\"\"\n",
    "    Compute RMSE and R² between two 1D arrays (or Series), dropping\n",
    "    the first `drop_initial` samples of the overlap before calculation.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    # Interpolate if lengths differ\n",
    "    if len(y_true) != len(y_pred):\n",
    "        x_old = np.linspace(0, 1, len(y_pred))\n",
    "        x_new = np.linspace(0, 1, len(y_true))\n",
    "        y_pred = np.interp(x_new, x_old, y_pred)\n",
    "\n",
    "    # Mask out NaNs\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    y_t = y_true[mask]\n",
    "    y_p = y_pred[mask]\n",
    "\n",
    "    # Drop the first `drop_initial` samples\n",
    "    if len(y_t) > drop_initial:\n",
    "        y_t = y_t[drop_initial:]\n",
    "        y_p = y_p[drop_initial:]\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = rmse_calc(y_t, y_p)\n",
    "\n",
    "    # Compute R² via linear regression (shape‐only: r² of correlation)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(y_t, y_p)\n",
    "    r2 = r_value ** 2\n",
    "\n",
    "    return rmse, r2\n",
    "\n",
    "def mean_ci(lst):\n",
    "    mat = pd.concat(lst,axis=1)\n",
    "    m   = mat.mean(axis=1)\n",
    "    ci  = 1.96 * mat.std(axis=1)/np.sqrt(mat.shape[1])\n",
    "    return m,ci\n",
    "\n",
    "# END\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert c3d files to .mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3dFilePath = msk.ui.select_file()\n",
    "\n",
    "subject = os.path.basename(os.path.dirname(c3dFilePath))\n",
    "trial_folder = os.path.basename(c3dFilePath).replace('.c3d','')\n",
    "\n",
    "print(f\"Subject: {subject}\")\n",
    "print(f\"Trial: {trial_folder}\")\n",
    "legs = ['r', 'l']\n",
    "\n",
    "for leg in legs:\n",
    "    leg_folder_name = trial_folder + f'_{leg}1'\n",
    "    leg_folder = os.path.join(os.path.dirname(c3dFilePath), leg_folder_name)\n",
    "    if not os.path.exists(leg_folder):\n",
    "        os.mkdir(leg_folder)\n",
    "        print(f\"Folder created: {leg_folder}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {leg_folder}\")\n",
    "        \n",
    "    if leg == 'r':\n",
    "        columns_to_mot = ['RGLTMED','RRF','RADDLONG','RST', 'RBF','RTA','RGM']\n",
    "    else:\n",
    "        columns_to_mot = ['LGLTMED','LRF','LADDLONG','LST','LBF','LTA','LGM'] \n",
    "\n",
    "    \n",
    "    # Export analog data to csv\n",
    "    analog_csv_path = export_analog(c3dFilePath, columns_to_mot=columns_to_mot)\n",
    "    \n",
    "    print(f\"Exported Analog CSV Path: {analog_csv_path}\")\n",
    "\n",
    "    # Process EMG signals\n",
    "    filtered_emg_path = filter_emg_signals(analog_csv_path, columns_to_mot)\n",
    "\n",
    "    # Normalise amplitude of EMG signals\n",
    "    normalised_emg_path = amplitude_normalise(filtered_emg_path)\n",
    "    \n",
    "    # convert to mot\n",
    "    emg_mot_path = csv_to_mot(normalised_emg_path)\n",
    "    \n",
    "    # move the file to the leg folder\n",
    "    want_it = True\n",
    "    if want_it:\n",
    "        # move the file to the folder\n",
    "        new_analog_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'analog_emg_signals.csv')\n",
    "        new_emg_mot_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'processed_emg_signals.mot')\n",
    "\n",
    "        try:\n",
    "            shutil.move(analog_csv_path, new_analog_path)\n",
    "            shutil.move(emg_mot_path, new_emg_mot_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually processing EMG data for TD children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emg_signals_manually(raw_emg_csv_path):\n",
    "    raw_emg_csv_path = Path(raw_emg_csv_path)\n",
    "\n",
    "    # Manually define EMG channels depending on leg side\n",
    "\n",
    "    # For RIGHT leg trials — uncomment this block when needed\n",
    "    # columns_to_mot = [\n",
    "    #     'RGLTMED',\n",
    "    #     'RRF',\n",
    "    #     'RADDLONG',\n",
    "    #     'RST',\n",
    "    #     'RTA',\n",
    "    #     'RGM'\n",
    "    # ]\n",
    "\n",
    "    #For LEFT leg trials — uncomment this block instead\n",
    "    columns_to_mot = [\n",
    "        'LGLTMED',\n",
    "        'LRF',\n",
    "        'LADDLONG',\n",
    "        'LST',\n",
    "        'LTA',\n",
    "        'LGM'\n",
    "    ]\n",
    "\n",
    "    # Process \n",
    "\n",
    "    print(f\"Processing EMG from: {raw_emg_csv_path}\")\n",
    "    print(f\"Using columns: {columns_to_mot}\")\n",
    "\n",
    "    # Step 1: Filter EMG\n",
    "    filtered_emg_path = filter_emg_signals(str(raw_emg_csv_path), columns_to_mot)\n",
    "\n",
    "    # Step 2: Normalize EMG\n",
    "    normalised_emg_path = amplitude_normalise(filtered_emg_path)\n",
    "\n",
    "    # Step 3: Convert to .mot\n",
    "    emg_mot_path = csv_to_mot(normalised_emg_path)\n",
    "\n",
    "    # Step 4: Move final .mot file to same folder\n",
    "    processed_emg_mot_path = raw_emg_csv_path.parent / 'processed_emg_signals.mot'\n",
    "    shutil.move(emg_mot_path, processed_emg_mot_path)\n",
    "\n",
    "    print(f\"Saved: {processed_emg_mot_path}\")\n",
    "    return str(processed_emg_mot_path)\n",
    "\n",
    "\n",
    "\n",
    "process_emg_signals_manually(\n",
    "    simulations_dir / \"TD026\" / \"normal3_l1\" / \"trial3.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start all files from Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_l1'\n",
    "data = os_analysis.subjects[subject][trial_name].emg.data\n",
    "\n",
    "if data is None:\n",
    "    print(f\"EMG data for subject {subject}, trial {trial_name} is not loaded correctly.\")\n",
    "else:\n",
    "    print(\"EMG data loaded successfully.\")\n",
    "    data['time'] = data['time'] - data['time'].iloc[0]\n",
    "\n",
    "print(data)\n",
    "\n",
    "def save_new_emg_file(data, file_path):\n",
    "    header = header_mot(data, \"new_emg_signals\")\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(header + '\\n')\n",
    "        f.write('\\t'.join(map(str, data.columns)) + '\\n')\n",
    "        for index, row in data.iterrows():\n",
    "            f.write('\\t'.join(map(str, row.values)) + '\\n')\n",
    "    print(f\"New EMG data saved at: {file_path}\")\n",
    "\n",
    "new_emg_file_path = os.path.join(one_dir_up, 'Simulations', subject, trial_name, 'new_emg_signals.mot')\n",
    "save_new_emg_file(data, new_emg_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check times in all files for simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()\n",
    "\n",
    "subject = 'TD026'\n",
    "trial_name = 'normal3_l1'\n",
    "\n",
    "#check times\n",
    "print(os_analysis.subjects[subject][trial_name].ik.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].id.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].emg.time_range)\n",
    "\n",
    "# Define relative paths to the files\n",
    "id_file = os_analysis.subjects[subject][trial_name].id.path\n",
    "ik_file = os_analysis.subjects[subject][trial_name].ik.path\n",
    "emg_file = os_analysis.subjects[subject][trial_name].emg.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial in trial_list:\n",
    "        try:\n",
    "            os_analysis.subjects[subject][trial].change_grf_xml_path()\n",
    "            os_analysis.subjects[subject][trial].run_ID(osim_modelPath=os_analysis.subjects[subject]['model'], \n",
    "                                                            coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "                                                            output_file=os_analysis.subjects[subject][trial].id.path, \n",
    "                                                            external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "                                                            LowpassCutoffFrequency=6, \n",
    "                                                            run_tool=True)\n",
    "            \n",
    "            print(f\"ID ran successfully for {subject} - {trial}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running ID for {subject} - {trial}\")\n",
    "            print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_SO(model_path, coordinates_file, actuators_file_path, run_tool=True):\n",
    "    '''\n",
    "    Function to run Static Optimization using the OpenSim API.\n",
    "    \n",
    "    Inputs:\n",
    "            modelpath(str): path to the OpenSim model file\n",
    "            trialpath(str): path to the trial folder\n",
    "            actuators_file_path(str): path to the actuators file\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    trialpath = os.path.dirname(coordinates_file)   \n",
    "    # create directories\n",
    "    results_directory = os.path.relpath(trialpath, trialpath)\n",
    "    coordinates_file =  os.path.relpath(trialpath, coordinates_file)\n",
    "    modelpath_relative = os.path.relpath(model_path, trialpath)\n",
    "\n",
    "    # create a local copy of the actuator file path and update name\n",
    "    actuators_file_path = os.path.relpath(actuators_file_path, trialpath)\n",
    "\n",
    "    # start model\n",
    "    OsimModel = msk.osim.Model(modelpath_relative)\n",
    "\n",
    "    # Get mot data to determine time range\n",
    "    motData = msk.osim.Storage(coordinates_file)\n",
    "\n",
    "    # Get initial and intial time\n",
    "    initial_time = motData.getFirstTime()\n",
    "    final_time = motData.getLastTime()\n",
    "\n",
    "    # Static Optimization\n",
    "    so = msk.osim.StaticOptimization()\n",
    "    so.setName('StaticOptimization')\n",
    "    so.setModel(OsimModel)\n",
    "\n",
    "    # Set other parameters as needed\n",
    "    so.setStartTime(initial_time)\n",
    "    so.setEndTime(final_time)\n",
    "    so.setMaxIterations(25)\n",
    "\n",
    "    analyzeTool_SO = msk.classes.osimSetup.create_analysis_tool(coordinates_file,modelpath_relative,results_directory)\n",
    "    analyzeTool_SO.getAnalysisSet().cloneAndAppend(so)\n",
    "    analyzeTool_SO.getForceSetFiles().append(actuators_file_path)\n",
    "    analyzeTool_SO.setReplaceForceSet(False)\n",
    "    OsimModel.addAnalysis(so)\n",
    "\n",
    "    analyzeTool_SO.printToXML(\".\\setup_so.xml\")\n",
    "\n",
    "    analyzeTool_SO = msk.osim.AnalyzeTool(\".\\setup_so.xml\")\n",
    "\n",
    "    trial = os.path.basename(trialpath)\n",
    "    print(f\"so for {trial}\")\n",
    "\n",
    "    # run\n",
    "    if run_tool:\n",
    "        analyzeTool_SO.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_SO(model_path=os_analysis.subjects[subject]['model'], \n",
    "        coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "        actuators_file_path=os_analysis.subjects[subject][trial].id.path, \n",
    "        external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "        LowpassCutoffFrequency=6, \n",
    "        run_tool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create CEINMS XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC006'\n",
    "trial_name = 'trial2_l1'\n",
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#check times\n",
    "print(os_analysis.subjects[subject][trial_name].ik.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].id.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].emg.time_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ['GLTMED', 'RF', 'ADDLONG', 'ST', 'TA', 'GM']\n",
    "\n",
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "            leg = trial_name[-2]\n",
    "            try:\n",
    "                trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "                subject_path = os.path.dirname(trial_path)\n",
    "                model = os.path.join(subject_path, f'{subject}_v3.osim')\n",
    "                \n",
    "                # check if IK file exists\n",
    "                if not os.path.exists(os_analysis.subjects[subject][trial_name].ik.path):\n",
    "                    try:\n",
    "                        shutil.rmtree(trial_path)\n",
    "                    except:\n",
    "                        pass \n",
    "                    \n",
    "                    print(f\"IK file not found for {subject} - {trial_name}. Skipping...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    # make ceims folder \n",
    "                    os.makedirs(os.path.join(trial_path, 'ceinms'), exist_ok=True)\n",
    "                \n",
    "                os_analysis.subjects[subject][trial_name].create_ceinms_files(osim_model_path=model,\n",
    "                                                                            leg=leg,\n",
    "                                                                            input_signals=signals)\n",
    "            except:\n",
    "                print(f\"Error creating CEINMS files for {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            print(f\"CEINMS files created for {subject} - {trial_name} - {leg}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Single Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_list = os_analysis.subjects[subject].keys()\n",
    "for trial_name in trial_list:\n",
    "    if hasattr(os_analysis.subjects[subject][trial_name], 'path'):\n",
    "        if os.path.isdir(os_analysis.subjects[subject][trial_name].path):\n",
    "            print(f\"CEINMS file exists for {subject} - {trial_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'trial2_r1'\n",
    "\n",
    "code_path = os.getcwd()\n",
    "xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_cal_setup.path\n",
    "os.path.join(os.path.dirname(code_path), 'Simulations', subject, trial_name, 'ceinms', 'calibrationSetup.xml')\n",
    "os.chdir(os.path.dirname(xml_setup_file))\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "print(str(command))\n",
    "#print(os.getcwd())\n",
    "result = subprocess.run(command, capture_output=True, text=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Single Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "xml_setup_file = os.path.join(simulations_dir, subject, 'trial2_r1', 'ceinms', 'executionSetup.xml')\n",
    "command = \" \".join([ceinms_install_path + \"\\CEINMS.exe -S\", xml_setup_file])\n",
    "\n",
    "os.chdir(os.path.dirname(xml_setup_file))\n",
    "print(command)\n",
    "result = subprocess.run(command)\n",
    "print(f'file save in {os.path.dirname(xml_setup_file)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (only right leg)\n",
    "\n",
    "subject_list = ['PC002', 'PC003', 'PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1', 'trial2', 'trial3', 'normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "# clear output\n",
    "clear_output()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.getcwd()\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "\n",
    "# Uncomment the following line to run calibration for all subjects\n",
    "pc_subject_list = subject_list\n",
    "\n",
    "# Filter subject list to include only PC children\n",
    "#pc_subject_list = [subj for subj in subject_list if subj.startswith('PC')]\n",
    "\n",
    "for subject in pc_subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "        leg = trial_name[-2]\n",
    "        try:\n",
    "            trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "            # Change working directory to trial path\n",
    "            os.chdir(trial_path)\n",
    "            \n",
    "            xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_cal_setup.path\n",
    "            \n",
    "            command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "            \n",
    "            result = subprocess.run(command, capture_output=True, text=True, check=True)            \n",
    "\n",
    "            print(f\"Calibration successful for {subject} - {trial_name} - {leg}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running calibration for {subject} - {trial_name} - {leg}\")\n",
    "            print(e)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.getcwd()\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "\n",
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "            leg = trial_name[-2]\n",
    "            try:\n",
    "                trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "                \n",
    "                \n",
    "                xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_execution_setup.path\n",
    "                tree = ET.parse(xml_setup_file)\n",
    "                root = tree.getroot()\n",
    "                output_dir = root.find('.//outputDirectory').text\n",
    "                output_dir = os.path.join(os.path.dirname(xml_setup_file), output_dir)\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                \n",
    "                # change working directory to trial path\n",
    "                os.chdir(output_dir)\n",
    "                                \n",
    "                command = \" \".join([ceinms_install_path + \"\\CEINMS.exe -S\", xml_setup_file])\n",
    "                \n",
    "                result = subprocess.run(command)            \n",
    "\n",
    "                print(f\"Execution successful for {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            except:\n",
    "                print(f\"Error on {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            print(f\"CEINMS done for {subject} - {trial_name} - {leg}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare CEINMS forces with SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC003'\n",
    "trial_name = 'trial1_r1'\n",
    "ceinms_forces = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'MuscleForces.sto'))\n",
    "so_forces = import_file(os.path.join(simulations_dir, subject, trial_name, 'Results_SO_and_MA', 'StaticOptimization_force.sto'))\n",
    "\n",
    "# print(ceinms_forces)\n",
    "# print(so_forces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the data to the same time range\n",
    "start_time = max(ceinms_forces['time'].iloc[0], so_forces['time'].iloc[0])\n",
    "end_time = min(ceinms_forces['time'].iloc[-1], so_forces['time'].iloc[-1])\n",
    "\n",
    "ceinms_forces = ceinms_forces[(ceinms_forces['time'] >= start_time) & (ceinms_forces['time'] <= end_time)]\n",
    "so_forces = so_forces[(so_forces['time'] >= start_time) & (so_forces['time'] <= end_time)]\n",
    "\n",
    "muscles_to_plot = [\n",
    "    'glut_med1_r', 'glut_med2_r', 'glut_med3_r', 'glut_min1_r', 'glut_min2_r', 'glut_min3_r', \n",
    "    'semimem_r', 'semiten_r', 'bifemlh_r', 'bifemsh_r', 'sar_r', 'add_long_r', 'add_brev_r', \n",
    "    'add_mag1_r', 'add_mag2_r', 'add_mag3_r', 'tfl_r', 'pect_r', 'grac_r', 'glut_max1_r', \n",
    "    'glut_max2_r', 'glut_max3_r', 'iliacus_r', 'psoas_r', 'quad_fem_r', 'gem_r', 'peri_r', \n",
    "    'rect_fem_r', 'vas_med_r', 'vas_int_r', 'vas_lat_r', 'med_gas_r', 'lat_gas_r', 'soleus_r', \n",
    "    'tib_post_r', 'flex_dig_r', 'flex_hal_r', 'tib_ant_r', 'per_brev_r', 'per_long_r', 'per_tert_r', \n",
    "    'ext_dig_r', 'ext_hal_r', 'glut_med1_l', 'glut_med2_l', 'glut_med3_l', 'glut_min1_l', 'glut_min2_l', \n",
    "    'glut_min3_l', 'semimem_l', 'semiten_l', 'bifemlh_l', 'bifemsh_l', 'sar_l', 'add_long_l', 'add_brev_l', \n",
    "    'add_mag1_l', 'add_mag2_l', 'add_mag3_l', 'tfl_l', 'pect_l', 'grac_l', 'glut_max1_l', 'glut_max2_l', \n",
    "    'glut_max3_l', 'iliacus_l', 'psoas_l', 'quad_fem_l', 'gem_l', 'peri_l', 'rect_fem_l', 'vas_med_l', \n",
    "    'vas_int_l', 'vas_lat_l', 'med_gas_l', 'lat_gas_l', 'soleus_l', 'tib_post_l', 'flex_dig_l', 'flex_hal_l', \n",
    "    'tib_ant_l', 'per_brev_l', 'per_long_l', 'per_tert_l', 'ext_dig_l', 'ext_hal_l', 'ercspn_r', 'ercspn_l', \n",
    "    'intobl_r', 'intobl_l', 'extobl_r', 'extobl_l'\n",
    "]\n",
    "colours = ['b', 'r']\n",
    "fig, axes = plt.subplots(len(muscles_to_plot), 1, figsize=(10, 5 * len(muscles_to_plot)))\n",
    "\n",
    "for i, muscle in enumerate(muscles_to_plot):\n",
    "    \n",
    "    if muscle not in ceinms_forces.columns:\n",
    "        continue\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ceinms_color = 'b'\n",
    "    so_color = 'r'\n",
    "    ax.plot(ceinms_forces['time'], ceinms_forces[muscle], label=f'CEINMS - {muscle}', color=ceinms_color)\n",
    "    ax.plot(so_forces['time'], so_forces[muscle], label=f'SO - {muscle}', color=so_color)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Force (N)')\n",
    "    ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Force (N)')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files for the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_r1'\n",
    "leg = 'l' if (subject == 'PC006') else 'r'\n",
    "ceinms_activations = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'Activations.sto'))\n",
    "so_activations = import_file(os.path.join(simulations_dir, subject, trial_name, 'Results_SO_and_MA', 'StaticOptimization_activation.sto'))\n",
    "emg_data = import_file(os.path.join(simulations_dir, subject, trial_name, 'processed_emg_signals.mot'))\n",
    "so_force = import_file(os.path.join(simulations_dir, subject, trial_name, 'Results_SO_and_MA', 'StaticOptimization_force.sto'))\n",
    "torques = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'Torques.sto'))\n",
    "id = import_file(os.path.join(simulations_dir, subject, trial_name, 'inverse_dynamics.sto'))\n",
    "pc_muscle_forces = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'MuscleForces.sto'))\n",
    "ik = import_file(os.path.join(simulations_dir, subject, trial_name, 'Visual3d_SIMM_input.mot'))\n",
    "\n",
    "\n",
    "joint_suffix = {\n",
    "    'hip': {\n",
    "        'so': f'hip_flexion_{leg}',\n",
    "        'ceinms': f'hip_flexion_{leg}',\n",
    "        'id': f'hip_flexion_{leg}_moment'\n",
    "    },\n",
    "    'knee': {\n",
    "        'so': f'knee_angle_{leg}',\n",
    "        'ceinms': f'knee_angle_{leg}',\n",
    "        'id': f'knee_angle_{leg}_moment'\n",
    "    },\n",
    "    'ankle': {\n",
    "        'so': f'ankle_angle_{leg}',\n",
    "        'ceinms': f'ankle_angle_{leg}',\n",
    "        'id': f'ankle_angle_{leg}_moment'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load moment arm files\n",
    "moment_arm_files = {\n",
    "    joint: os.path.join(\n",
    "        simulations_dir, subject, trial_name, 'Results_SO_and_MA',\n",
    "        f'MuscleAnalysis_MomentArm_{joint_suffix[joint][\"so\"]}.sto'\n",
    "    )\n",
    "    for joint in ['hip', 'knee', 'ankle']\n",
    "}\n",
    "\n",
    "# Load the files into DataFrames\n",
    "moment_arms = {\n",
    "    joint_suffix[joint]['so']: import_file(path)\n",
    "    for joint, path in moment_arm_files.items()\n",
    "}\n",
    "\n",
    "# Muscle groups (right leg only)\n",
    "muscle_groups = {\n",
    "    'hip_extensors': ['add_long_r', 'add_mag1_r', 'add_mag2_r', 'add_mag3_r', 'bifemlh_r', 'glut_max1_r', 'glut_max2_r', 'glut_max3_r', 'glut_med3_r', 'glut_min3_r', 'semimem_r', 'semiten_r'],\n",
    "    'hip_flexors': ['add_brev_r', 'add_long_r', 'glut_med1_r', 'glut_min1_r', 'grac_r', 'iliacus_r', 'pect_r', 'psoas_r', 'rect_fem_r', 'sar_r', 'tfl_r'],\n",
    "    'knee_extensors': ['rect_fem_r', 'vas_int_r', 'vas_lat_r', 'vas_med_r'],\n",
    "    'knee_flexors': ['bifemlh_r', 'bifemsh_r', 'grac_r', 'lat_gas_r', 'med_gas_r', 'sar_r', 'semimem_r', 'semiten_r'],\n",
    "    'ankle_plantarflexors': ['flex_dig_r', 'flex_hal_r', 'lat_gas_r', 'med_gas_r', 'per_brev_r', 'per_long_r', 'soleus_r', 'tib_post_r'],\n",
    "    'ankle_dorsiflexors': ['ext_dig_r', 'ext_hal_r', 'per_tert_r', 'tib_ant_r']\n",
    "}\n",
    "# Muscle groups (left leg only)\n",
    "muscle_groups_left = {\n",
    "    'hip_extensors': ['add_long_l', 'add_mag1_l', 'add_mag2_l', 'add_mag3_l', 'bifemlh_l', 'glut_max1_l', 'glut_max2_l', 'glut_max3_l', 'glut_med3_l', 'glut_min3_l', 'semimem_l', 'semiten_l'],\n",
    "    'hip_flexors': ['add_brev_l', 'add_long_l', 'glut_med1_l', 'glut_min1_l', 'grac_l', 'iliacus_l', 'pect_l', 'psoas_l', 'rect_fem_l', 'sar_l', 'tfl_l'],\n",
    "    'knee_extensors': ['rect_fem_l', 'vas_int_l', 'vas_lat_l', 'vas_med_l'],\n",
    "    'knee_flexors': ['bifemlh_l', 'bifemsh_l', 'grac_l', 'lat_gas_l', 'med_gas_l', 'sar_l', 'semimem_l', 'semiten_l'],\n",
    "    'ankle_plantarflexors': ['flex_dig_l', 'flex_hal_l', 'lat_gas_l', 'med_gas_l', 'per_brev_l', 'per_long_l', 'soleus_l', 'tib_post_l'],\n",
    "    'ankle_dorsiflexors': ['ext_dig_l', 'ext_hal_l', 'per_tert_l', 'tib_ant_l']\n",
    "    \n",
    "}\n",
    "\n",
    "bodymass = {\n",
    "    'PC002': 31.35, 'PC003': 44.75, 'PC006': 25.75, 'PC013': 60.6,\n",
    "    'TD006': 21.75, 'TD013': 26.25, 'TD017': 25.80, 'TD021': 28.25,\n",
    "    'TD023': 23.3,  'TD026': 28.3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing joint kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects, trials, storage\n",
    "cp_subjects      = ['PC002','PC003','PC006','PC013']\n",
    "td_subjects      = ['TD006','TD013','TD017','TD021','TD023','TD026']\n",
    "cp_trials        = ['trial1_r1','trial2_r1','trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1','crouch2_r1','crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1','normal2_r1','normal3_r1']\n",
    "\n",
    "joints = ['hip','knee','ankle']\n",
    "cp_data   = {s:{j:[] for j in joints} for s in cp_subjects}\n",
    "td_crouch = {j:[] for j in joints}\n",
    "td_normal = {j:[] for j in joints}\n",
    "\n",
    "# load CP data (PC006 uses left leg)\n",
    "for sub in cp_subjects:\n",
    "    leg    = 'l' if sub=='PC006' else 'r'\n",
    "    trials = ['trial2_l1'] if sub=='PC006' else cp_trials\n",
    "    for tr in trials:\n",
    "        fp = simulations_dir/sub/tr/'Visual3d_SIMM_input.mot'\n",
    "        if not fp.exists(): \n",
    "            continue\n",
    "        df = import_file(str(fp))\n",
    "        dfj = df[[f'hip_flexion_{leg}',f'knee_angle_{leg}',f'ankle_angle_{leg}']]\n",
    "        dfj = resample_to_percent_phase(dfj)\n",
    "        cp_data[sub]['hip'].append (dfj[f'hip_flexion_{leg}'])\n",
    "        cp_data[sub]['knee'].append(dfj[f'knee_angle_{leg}'])\n",
    "        cp_data[sub]['ankle'].append(dfj[f'ankle_angle_{leg}'])\n",
    "\n",
    "# average across trials\n",
    "for sub in cp_subjects:\n",
    "    for j in joints:\n",
    "        L = cp_data[sub][j]\n",
    "        cp_data[sub][j] = pd.concat(L, axis=1).mean(axis=1)\n",
    "\n",
    "# load TD crouch & normal (always right leg)\n",
    "for sub in td_subjects:\n",
    "    for tr in td_crouch_trials:\n",
    "        fp = simulations_dir/sub/tr/'Visual3d_SIMM_input.mot'\n",
    "        if not fp.exists(): continue\n",
    "        df = import_file(str(fp))[[ 'hip_flexion_r','knee_angle_r','ankle_angle_r' ]]\n",
    "        df = resample_to_percent_phase(df)\n",
    "        td_crouch['hip'] .append(df['hip_flexion_r'])\n",
    "        td_crouch['knee'].append(df['knee_angle_r'])\n",
    "        td_crouch['ankle'].append(df['ankle_angle_r'])\n",
    "    for tr in td_normal_trials:\n",
    "        fp = simulations_dir/sub/tr/'Visual3d_SIMM_input.mot'\n",
    "        if not fp.exists(): continue\n",
    "        df = import_file(str(fp))[[ 'hip_flexion_r','knee_angle_r','ankle_angle_r' ]]\n",
    "        df = resample_to_percent_phase(df)\n",
    "        td_normal['hip'] .append(df['hip_flexion_r'])\n",
    "        td_normal['knee'].append(df['knee_angle_r'])\n",
    "        td_normal['ankle'].append(df['ankle_angle_r'])\n",
    "\n",
    "# compute mean ±95%CI for TD groups\n",
    "tdc_stats = { j:mean_ci(td_crouch[j]) for j in joints }\n",
    "tdn_stats = { j:mean_ci(td_normal[j]) for j in joints }\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 20,\n",
    "    'axes.titlesize': 24,      \n",
    "    'axes.labelsize': 20,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 20,     \n",
    "    'lines.linewidth': 2.5,\n",
    "})\n",
    "x = np.linspace(0,100,101)\n",
    "fig, axes = plt.subplots(1,3,figsize=(32,8), sharex=True)\n",
    "\n",
    "cp_colors = {'PC002':'tab:blue','PC003':'tab:purple','PC006':'tab:olive','PC013':'tab:red'}\n",
    "tdc_color = 'tab:orange'\n",
    "tdn_color = 'tab:green'\n",
    "\n",
    "y_limits = {\n",
    "    'hip':   (-10, 70),\n",
    "    'knee':  (0,   80),\n",
    "    'ankle': (-5,  40)\n",
    "}\n",
    "\n",
    "# title map:\n",
    "title_map = {\n",
    "    'hip':   'Hip Flexion',\n",
    "    'knee':  'Knee Flexion',\n",
    "    'ankle': 'Ankle Dorsiflexion'\n",
    "}\n",
    "\n",
    "for i, joint in enumerate(joints):\n",
    "    ax = axes[i]\n",
    "    flip = joint == 'knee'\n",
    "\n",
    "    # CP individuals\n",
    "    for sub in cp_subjects:\n",
    "        y = -cp_data[sub][joint] if flip else cp_data[sub][joint]\n",
    "        ax.plot(x, y, color=cp_colors[sub], label=sub, linewidth=3)\n",
    "        \n",
    "    # TD crouch\n",
    "    m, ci = tdc_stats[joint]\n",
    "    m_plot = -m if flip else m\n",
    "    ax.plot(x, m_plot, color=tdc_color, label='TD crouch', linewidth=3)\n",
    "    ax.fill_between(x, m_plot - ci, m_plot + ci, color=tdc_color, alpha=0.2)\n",
    "\n",
    "    # TD normal\n",
    "    m, ci = tdn_stats[joint]\n",
    "    m_plot = -m if flip else m\n",
    "    ax.plot(x, m_plot, color=tdn_color, label='TD normal', linewidth=3)\n",
    "    ax.fill_between(x, m_plot - ci, m_plot + ci, color=tdn_color, alpha=0.2)\n",
    "\n",
    "    ax.set_title(title_map[joint], fontsize=24)\n",
    "\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.set_ylim(*y_limits[joint])\n",
    "    ax.set_xlabel('Single‐leg support (%)')\n",
    "    # Add y-axis label manually next to each subplot\n",
    "    angle_labels = {\n",
    "    'hip':   'EXT (–) FLEX (+)',\n",
    "    'knee':  'EXT (–) FLEX (+)', \n",
    "    'ankle': 'PF (–) DF (+)'\n",
    "    }\n",
    "    ax.text(-0.06, 0.5, angle_labels[joint],\n",
    "        transform=ax.transAxes,\n",
    "        ha='center', va='center',\n",
    "        rotation=90, fontsize=20)\n",
    "    ax.grid(False)\n",
    "\n",
    "# single legend on the right\n",
    "\n",
    "handles = (\n",
    "    [Line2D([0],[0],color=cp_colors[s],lw=2) for s in cp_subjects]\n",
    "    +\n",
    "    [Line2D([0],[0],color=tdc_color,lw=2),\n",
    "     Line2D([0],[0],color=tdn_color,lw=2)]\n",
    ")\n",
    "labels = cp_subjects + ['TD crouch','TD normal']\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.0,0.5), frameon=False, fontsize=24)\n",
    "fig.text(0.01, 0.5, 'Angle (°)', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "plt.tight_layout(rect=[0.03,0,0.95,1])\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig.savefig(os.path.join(simulations_dir, 'Plots_for_thesis', 'joint_kinematics.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD plots with only shaded area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'font.size': 22,\n",
    "    'axes.titlesize': 26,\n",
    "    'axes.labelsize': 22,\n",
    "    'xtick.labelsize': 22,\n",
    "    'ytick.labelsize': 22,\n",
    "    'legend.fontsize': 22,\n",
    "    'lines.linewidth': 2.5,\n",
    "})\n",
    "\n",
    "x = np.linspace(0, 100, 101)\n",
    "\n",
    "cp_colors = {'PC002':'tab:blue','PC003':'tab:purple','PC006':'tab:olive','PC013':'tab:red'}\n",
    "tdc_color = 'tab:orange'\n",
    "tdn_color = 'tab:green'\n",
    "\n",
    "joints = ['hip', 'knee', 'ankle']\n",
    "\n",
    "y_limits = {\n",
    "    'hip':   (-10, 70),\n",
    "    'knee':  (0, 80),\n",
    "    'ankle': (-5, 40)\n",
    "}\n",
    "\n",
    "title_map = {\n",
    "    'hip':   'Hip Flexion',\n",
    "    'knee':  'Knee Flexion',\n",
    "    'ankle': 'Ankle Dorsiflexion'\n",
    "}\n",
    "\n",
    "angle_labels = {\n",
    "    'hip':   'EXT (–) FLEX (+)',\n",
    "    'knee':  'EXT (–) FLEX (+)',\n",
    "    'ankle': 'PF (–) DF (+)'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(32, 12), sharex=True)\n",
    "\n",
    "# ——— Top row: CP + TD CROUCH ———\n",
    "for i, joint in enumerate(joints):\n",
    "    ax = axes[0, i]\n",
    "\n",
    "    # CP individuals\n",
    "    for sub in cp_subjects:\n",
    "        y = -cp_data[sub][joint] if joint == 'knee' else cp_data[sub][joint]\n",
    "        ax.plot(x, y, color=cp_colors[sub], linewidth=3)\n",
    "\n",
    "    # TD crouch \n",
    "    m, ci = tdc_stats[joint]\n",
    "    m = -m if joint == 'knee' else m\n",
    "    ax.fill_between(x, m - ci, m + ci, color=tdc_color, alpha=0.2)\n",
    "\n",
    "    ax.set_title(title_map[joint], fontsize=26)\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(*y_limits[joint])\n",
    "    ax.text(-0.1, 0.5, angle_labels[joint],\n",
    "            transform=ax.transAxes,\n",
    "            ha='center', va='center',\n",
    "            rotation=90, fontsize=22)\n",
    "    ax.grid(False)\n",
    "\n",
    "# Bottom row: CP + TD NORMAL\n",
    "for i, joint in enumerate(joints):\n",
    "    ax = axes[1, i]\n",
    "\n",
    "    # CP individuals\n",
    "    for sub in cp_subjects:\n",
    "        y = -cp_data[sub][joint] if joint == 'knee' else cp_data[sub][joint]\n",
    "        ax.plot(x, y, color=cp_colors[sub], linewidth=3)\n",
    "\n",
    "    # TD normal\n",
    "    m, ci = tdn_stats[joint]\n",
    "    m = -m if joint == 'knee' else m\n",
    "    ax.fill_between(x, m - ci, m + ci, color=tdn_color, alpha=0.2)\n",
    "\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(*y_limits[joint])\n",
    "    ax.set_xlabel('Single‐leg support (%)', fontsize=22)\n",
    "    ax.text(-0.1, 0.5, angle_labels[joint],\n",
    "            transform=ax.transAxes,\n",
    "            ha='center', va='center',\n",
    "            rotation=90, fontsize=22)\n",
    "    ax.grid(False)\n",
    "\n",
    "# Global y-axis label\n",
    "fig.text(0.01, 0.5, 'Angle (°)', va='center', rotation='vertical', fontsize=28)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.lines import Line2D\n",
    "handles = (\n",
    "    [Line2D([0],[0], color=cp_colors[s], lw=2) for s in cp_subjects] +\n",
    "    [Line2D([0],[0], color=tdc_color, lw=10, alpha=0.2),\n",
    "     Line2D([0],[0], color=tdn_color, lw=10, alpha=0.2)]\n",
    ")\n",
    "labels = cp_subjects + ['TD crouch', 'TD normal']\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.0, 0.5), frameon=False, fontsize=22)\n",
    "\n",
    "plt.tight_layout(rect=[0.03, 0, 0.95, 1])\n",
    "fig.savefig(os.path.join(simulations_dir, 'Plots_for_thesis', 'joint_kinematics_combined.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing joint moments (inverse dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_subjects      = ['PC002','PC003','PC006','PC013']\n",
    "td_subjects      = ['TD006','TD013','TD017','TD021','TD023','TD026']\n",
    "cp_trials        = ['trial1_r1','trial2_r1','trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1','crouch2_r1','crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1','normal2_r1','normal3_r1']\n",
    "\n",
    "bodymass = {\n",
    "    'PC002':31.35,'PC003':44.75,'PC006':25.75,'PC013':60.6,\n",
    "    'TD006':21.75,'TD013':26.25,'TD017':25.80,'TD021':28.25,'TD023':23.3,'TD026':28.3\n",
    "}\n",
    "\n",
    "joints = ['hip','knee','ankle']\n",
    "# Base inverse‐dynamics column names (right leg)\n",
    "joint_suffix = {\n",
    "    'hip':   {'id':'hip_flexion_r_moment'},\n",
    "    'knee':  {'id':'knee_angle_r_moment'},\n",
    "    'ankle': {'id':'ankle_angle_r_moment'}\n",
    "}\n",
    "# Left leg name for PC006\n",
    "for j in joints:\n",
    "    joint_suffix[j]['id_l'] = joint_suffix[j]['id'].replace('_r_', '_l_')\n",
    "\n",
    "# Containers\n",
    "cp_data   = {s:{j:[] for j in joints} for s in cp_subjects}\n",
    "td_crouch = {j:[] for j in joints}\n",
    "td_normal = {j:[] for j in joints}\n",
    "\n",
    "\n",
    "# load & process CP subjects\n",
    "\n",
    "for sub in cp_subjects:\n",
    "    use_left = (sub == 'PC006')\n",
    "    trials   = ['trial2_l1'] if use_left else cp_trials\n",
    "\n",
    "    for tr in trials:\n",
    "        fp = simulations_dir/sub/tr/'inverse_dynamics.sto'\n",
    "        if not fp.exists(): \n",
    "            continue\n",
    "        df = load_sto(fp)\n",
    "\n",
    "        # common time window\n",
    "        t0, t1 = df.time.iloc[0], df.time.iloc[-1]\n",
    "        df_crop = crop_time(df, t0, t1)\n",
    "        df_norm = normalize_time(df_crop, t0, t1 - t0)\n",
    "\n",
    "        for j in joints:\n",
    "            # pick left column if PC006 & present, else right\n",
    "            left_key  = joint_suffix[j]['id_l']\n",
    "            right_key = joint_suffix[j]['id']\n",
    "            if use_left and left_key in df_norm.columns:\n",
    "                key = left_key\n",
    "            elif right_key in df_norm.columns:\n",
    "                key = right_key\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # resample & normalize to body mass\n",
    "            ser = resample_to_percent_phase(df_norm[['time', key]])[key]\n",
    "            ser = ser / bodymass[sub]\n",
    "            cp_data[sub][j].append(ser)\n",
    "\n",
    "# average CP across trials\n",
    "for sub in cp_subjects:\n",
    "    for j in joints:\n",
    "        cp_data[sub][j] = pd.concat(cp_data[sub][j], axis=1).mean(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# load & process TD subjects\n",
    "\n",
    "for sub in td_subjects:\n",
    "    # crouch\n",
    "    for tr in td_crouch_trials:\n",
    "        fp = simulations_dir/sub/tr/'inverse_dynamics.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        t0, t1 = df.time.iloc[0], df.time.iloc[-1]\n",
    "        df_norm = normalize_time(crop_time(df, t0, t1), t0, t1 - t0)\n",
    "        for j in joints:\n",
    "            key = joint_suffix[j]['id']\n",
    "            if key in df_norm.columns:\n",
    "                ser = resample_to_percent_phase(df_norm[['time', key]])[key]\n",
    "                td_crouch[j].append(ser / bodymass[sub])\n",
    "    # normal\n",
    "    for tr in td_normal_trials:\n",
    "        fp = simulations_dir/sub/tr/'inverse_dynamics.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        t0, t1 = df.time.iloc[0], df.time.iloc[-1]\n",
    "        df_norm = normalize_time(crop_time(df, t0, t1), t0, t1 - t0)\n",
    "        for j in joints:\n",
    "            key = joint_suffix[j]['id']\n",
    "            if key in df_norm.columns:\n",
    "                ser = resample_to_percent_phase(df_norm[['time', key]])[key]\n",
    "                td_normal[j].append(ser / bodymass[sub])\n",
    "\n",
    "\n",
    "# compute TD mean ±95% CI\n",
    "tdc_stats = {j: mean_ci(td_crouch[j]) for j in joints}\n",
    "tdn_stats = {j: mean_ci(td_normal[j]) for j in joints}\n",
    "\n",
    "\n",
    "\n",
    "# plotting\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,             \n",
    "    'axes.titlesize': 20,        \n",
    "    'axes.labelsize': 18,        \n",
    "    'xtick.labelsize': 20,       \n",
    "    'ytick.labelsize': 16,       \n",
    "    'legend.fontsize': 16,       \n",
    "    'lines.linewidth': 2.5,      \n",
    "})\n",
    "x = np.linspace(0,100,101)\n",
    "fig, axes = plt.subplots(1,3,figsize=(32,8), sharex=True)\n",
    "\n",
    "cp_colors = {'PC002':'tab:blue','PC003':'tab:purple','PC006':'tab:olive','PC013':'tab:red'}\n",
    "tdc_color = 'tab:orange'\n",
    "tdn_color = 'tab:green'\n",
    "\n",
    "y_limits = {\n",
    "    'hip':   (-1.0,  1.5),\n",
    "    'knee':  (-0.5,  2),\n",
    "    'ankle': (-1.5,  0.5)\n",
    "}\n",
    "\n",
    "title_map = {\n",
    "    'hip':   'Hip Moment (Nm/kg)',\n",
    "    'knee':  'Knee Moment (Nm/kg)',\n",
    "    'ankle': 'Ankle Moment (Nm/kg)'\n",
    "}\n",
    "\n",
    "for i, j in enumerate(joints):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Flip hip and ankle, but not knee\n",
    "    flip = j in ['hip', 'ankle']\n",
    "    \n",
    "    # CP individuals\n",
    "    for sub in cp_subjects:\n",
    "        y = -cp_data[sub][j] if flip else cp_data[sub][j]\n",
    "        ax.plot(x, y, color=cp_colors[sub], label=sub)\n",
    "    \n",
    "    # TD crouch\n",
    "    m, ci = tdc_stats[j]\n",
    "    m_plot = -m if flip else m\n",
    "    ci_plot = ci\n",
    "    ax.plot(x, m_plot, color=tdc_color, label='TD crouch')\n",
    "    ax.fill_between(x, m_plot - ci_plot, m_plot + ci_plot, color=tdc_color, alpha=0.2)\n",
    "    \n",
    "    # TD normal\n",
    "    m, ci = tdn_stats[j]\n",
    "    m_plot = -m if flip else m\n",
    "    ci_plot = ci\n",
    "    ax.plot(x, m_plot, color=tdn_color, label='TD normal')\n",
    "    ax.fill_between(x, m_plot - ci_plot, m_plot + ci_plot, color=tdn_color, alpha=0.2)\n",
    "    \n",
    "    ax.set_title(title_map[j])\n",
    "    ax.set_xlim(0, 100)\n",
    "    \n",
    "    # Adjust y-limits: flipped for hip/ankle, original for knee\n",
    "    y_limits_flipped = {\n",
    "        'hip':   (-1.2, 0.7),\n",
    "        'knee':  (-0.5, 1.6),     # unchanged\n",
    "        'ankle': (-0.25, 1.3)\n",
    "    }\n",
    "    ax.set_ylim(*y_limits_flipped[j])\n",
    "    \n",
    "    ax.set_xlabel('Single-leg support (%)')\n",
    "    # Add y-axis label manually next to each subplot\n",
    "    angle_labels = {\n",
    "    'hip':   'FLEX (–) EXT (+)',\n",
    "    'knee':  'FLEX (–) EXT (+)',  # if you flipped it\n",
    "    'ankle': 'DF (–) PF (+)'\n",
    "    }\n",
    "    ax.text(-0.12, 0.5, angle_labels[j],\n",
    "        transform=ax.transAxes,\n",
    "        ha='center', va='center',\n",
    "        rotation=90, fontsize=16)\n",
    "    ax.grid(False)\n",
    "\n",
    "# shared legend on the right\n",
    "from matplotlib.lines import Line2D\n",
    "handles = (\n",
    "    [Line2D([0],[0], color=cp_colors[s], lw=2) for s in cp_subjects] +\n",
    "    [Line2D([0],[0], color=tdc_color , lw=2),\n",
    "     Line2D([0],[0], color=tdn_color , lw=2)]\n",
    ")\n",
    "labels = cp_subjects + ['TD crouch','TD normal']\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.0,0.5), frameon=False)\n",
    "fig.text(0.01, 0.5, 'Moment(Nm/kg)', va='center', rotation='vertical', fontsize=24)\n",
    "plt.tight_layout(rect=[0.03,0,0.95,1])\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig.savefig(os.path.join(simulations_dir, 'Plots_for_thesis', 'joint_moments.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD plots with only shaded area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'font.size': 22,\n",
    "    'axes.titlesize': 26,\n",
    "    'axes.labelsize': 22,\n",
    "    'xtick.labelsize': 22,\n",
    "    'ytick.labelsize': 22,\n",
    "    'legend.fontsize': 22,\n",
    "    'lines.linewidth': 2.5,\n",
    "})\n",
    "\n",
    "x = np.linspace(0, 100, 101)\n",
    "\n",
    "cp_colors = {'PC002':'tab:blue','PC003':'tab:purple','PC006':'tab:olive','PC013':'tab:red'}\n",
    "tdc_color = 'tab:orange'\n",
    "tdn_color = 'tab:green'\n",
    "\n",
    "joints = ['hip', 'knee', 'ankle']\n",
    "y_limits_flipped = {\n",
    "    'hip':   (-1.2, 0.7),\n",
    "    'knee':  (-0.5, 1.6),\n",
    "    'ankle': (-0.25, 1.3)\n",
    "}\n",
    "\n",
    "title_map = {\n",
    "    'hip':   'Hip Moment (Nm/kg)',\n",
    "    'knee':  'Knee Moment (Nm/kg)',\n",
    "    'ankle': 'Ankle Moment (Nm/kg)'\n",
    "}\n",
    "\n",
    "angle_labels = {\n",
    "    'hip':   'FLEX (–) EXT (+)',\n",
    "    'knee':  'FLEX (–) EXT (+)',\n",
    "    'ankle': 'DF (–) PF (+)'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(32, 12), sharex=True)\n",
    "\n",
    "# ——— Top row: CP + TD CROUCH ———\n",
    "for i, j in enumerate(joints):\n",
    "    ax = axes[0, i]\n",
    "    flip = j in ['hip', 'ankle']\n",
    "\n",
    "    # CP subjects\n",
    "    for sub in cp_subjects:\n",
    "        y = -cp_data[sub][j] if flip else cp_data[sub][j]\n",
    "        ax.plot(x, y, color=cp_colors[sub], label=sub)\n",
    "\n",
    "    # TD crouch shaded CI only\n",
    "    m, ci = tdc_stats[j]\n",
    "    m_plot = -m if flip else m\n",
    "    ax.fill_between(x, m_plot - ci, m_plot + ci, color=tdc_color, alpha=0.2)\n",
    "\n",
    "    ax.set_title(title_map[j], fontsize=26)\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(*y_limits_flipped[j])\n",
    "    ax.text(-0.13, 0.5, angle_labels[j], transform=ax.transAxes,\n",
    "            ha='center', va='center', rotation=90, fontsize=22)\n",
    "    ax.grid(False)\n",
    "\n",
    "# ——— Bottom row: CP + TD NORMAL ———\n",
    "for i, j in enumerate(joints):\n",
    "    ax = axes[1, i]\n",
    "    flip = j in ['hip', 'ankle']\n",
    "\n",
    "    # CP subjects\n",
    "    for sub in cp_subjects:\n",
    "        y = -cp_data[sub][j] if flip else cp_data[sub][j]\n",
    "        ax.plot(x, y, color=cp_colors[sub], label=sub)\n",
    "\n",
    "    # TD normal shaded CI only\n",
    "    m, ci = tdn_stats[j]\n",
    "    m_plot = -m if flip else m\n",
    "    ax.fill_between(x, m_plot - ci, m_plot + ci, color=tdn_color, alpha=0.2)\n",
    "\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(*y_limits_flipped[j])\n",
    "    ax.set_xlabel('Single-leg support (%)', fontsize=22)\n",
    "    ax.text(-0.13, 0.5, angle_labels[j], transform=ax.transAxes,\n",
    "            ha='center', va='center', rotation=90, fontsize=22)\n",
    "    ax.grid(False)\n",
    "\n",
    "# Global y-axis label\n",
    "fig.text(0.01, 0.5, 'Moment (Nm/kg)', va='center', rotation='vertical', fontsize=28)\n",
    "\n",
    "# Legend (shared)\n",
    "from matplotlib.lines import Line2D\n",
    "handles = (\n",
    "    [Line2D([0],[0], color=cp_colors[s], lw=2) for s in cp_subjects] +\n",
    "    [Line2D([0],[0], color=tdc_color, lw=10, alpha=0.2, label='TD crouch'),\n",
    "     Line2D([0],[0], color=tdn_color, lw=10, alpha=0.2, label='TD normal')]\n",
    ")\n",
    "labels = cp_subjects + ['TD crouch', 'TD normal']\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.0,0.5), frameon=False, fontsize=22)\n",
    "\n",
    "plt.tight_layout(rect=[0.03, 0, 0.95, 1])\n",
    "fig.savefig(os.path.join(simulations_dir, 'Plots_for_thesis', 'joint_moments_combined.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop data to the common range for the activation comparison\n",
    "\n",
    "\n",
    "ceinms_activations = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'Activations.sto'))\n",
    "so_activations = import_file(os.path.join(simulations_dir, subject, trial_name, 'Results_SO_and_MA', 'StaticOptimization_activation.sto'))\n",
    "emg_data = import_file(os.path.join(simulations_dir, subject, trial_name, 'processed_emg_signals.mot'))\n",
    "\n",
    "\n",
    "start_time = max(ceinms_activations['time'].iloc[0], so_activations['time'].iloc[0], emg_data['time'].iloc[0])\n",
    "end_time   = min(ceinms_activations['time'].iloc[-1], so_activations['time'].iloc[-1], emg_data['time'].iloc[-1])\n",
    "\n",
    "ceinms_activations = ceinms_activations[(ceinms_activations['time'] >= start_time) & (ceinms_activations['time'] <= end_time)]\n",
    "so_activations = so_activations[(so_activations['time'] >= start_time) & (so_activations['time'] <= end_time)]\n",
    "emg_data = emg_data[(emg_data['time'] >= start_time) & (emg_data['time'] <= end_time)]\n",
    "\n",
    "\n",
    "\n",
    "# Drop the first 3 frames of that cropped data\n",
    "ceinms_activations = ceinms_activations.iloc[3:].reset_index(drop=True)\n",
    "so_activations = so_activations.iloc[3:].reset_index(drop=True)\n",
    "emg_data = emg_data.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "# Re‑compute start/end on the cut data\n",
    "new_start = so_activations['time'].iloc[0]\n",
    "new_end   = so_activations['time'].iloc[-1]\n",
    "duration  = new_end - new_start\n",
    "\n",
    "# Normalize time\n",
    "for df in (so_activations, ceinms_activations, emg_data):\n",
    "    df['time'] = 100 * (df['time'] - new_start) / duration\n",
    "\n",
    "\n",
    "\n",
    "# EMG MAPPING and Filter Valid Muscles\n",
    "\n",
    "\n",
    "emg_mappings = {\n",
    "    'glut_med1_r':'RGLTMED','glut_med2_r':'RGLTMED','glut_med3_r':'RGLTMED',\n",
    "    'glut_min1_r':'RGLTMED','glut_min2_r':'RGLTMED','glut_min3_r':'RGLTMED',\n",
    "    'glut_max1_r':'RGLTMED','glut_max2_r':'RGLTMED','glut_max3_r':'RGLTMED',\n",
    "    'add_brev_r':'RADDLONG','add_long_r':'RADDLONG','grac_r':'RADDLONG',\n",
    "    'bifemlh_r':'RBF','bifemsh_r':'RBF','semimem_r':'RBF','semiten_r':'RBF',\n",
    "    'tib_ant_r':'RTA','ext_dig_r':'RTA','ext_hal_r':'RTA',\n",
    "    'rect_fem_r':'RRF','med_gas_r':'RGM','lat_gas_r':'RGM','soleus_r':'RGM'\n",
    "}\n",
    "\n",
    "\n",
    "valid_muscles = [\n",
    "    muscle for muscle, emg_channel in emg_mappings.items()\n",
    "    if muscle in ceinms_activations.columns and\n",
    "       muscle in so_activations.columns and\n",
    "       emg_channel in emg_data.columns\n",
    "]\n",
    "\n",
    "# Plotting the Activation Comparisons with RMSE/R² Annotations\n",
    "\n",
    "n = len(valid_muscles)\n",
    "cols = 6\n",
    "rows = int(np.ceil(n / cols))\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "target_length = len(so_activations['time'])\n",
    "\n",
    "for i, muscle in enumerate(valid_muscles):\n",
    "    emg_channel = emg_mappings[muscle]\n",
    "    \n",
    "    # Extract the curves from each DataFrame\n",
    "    x_so = so_activations['time']\n",
    "    y_so = so_activations[muscle]\n",
    "    \n",
    "    x_ceinms = ceinms_activations['time']\n",
    "    y_ceinms = ceinms_activations[muscle]\n",
    "    \n",
    "    x_emg = emg_data['time']\n",
    "    y_emg = emg_data[emg_channel]\n",
    "    \n",
    "    # Resample CEINMS and EMG curves to the target length if needed:\n",
    "    if len(x_ceinms) != target_length:\n",
    "        x_ceinms, y_ceinms = resample_curve(x_ceinms, y_ceinms, target_length)\n",
    "    if len(x_emg) != target_length:\n",
    "        x_emg, y_emg = resample_curve(x_emg, y_emg, target_length)\n",
    "\n",
    "    \n",
    "    # Plot the activation curves using the same time grid \n",
    "    axes[i].plot(x_so, y_ceinms, label='CEINMS', color='blue')\n",
    "    axes[i].plot(x_so, y_so, label='SO', color='orange')\n",
    "    axes[i].plot(x_so, y_emg, label='EMG', color='black')\n",
    "    axes[i].set_title(muscle)\n",
    "    axes[i].set_ylim(0, 1)\n",
    "    axes[i].set_xlim(0, 100)\n",
    "    \n",
    "    # Compute RMSE and R²: compare to EMG \n",
    "    so_rmse, so_r2 = compute_rmse_r2(y_emg, y_so)\n",
    "    ceinms_rmse, ceinms_r2 = compute_rmse_r2(y_emg, y_ceinms)\n",
    "    \n",
    "    # Annotate the subplot with the computed metrics\n",
    "    annotation_text = (f\"SO: RMSE={so_rmse:.2f}, R²={so_r2:.2f}\\n\"\n",
    "                       f\"CEINMS: RMSE={ceinms_rmse:.2f}, R²={ceinms_r2:.2f}\")\n",
    "    axes[i].text(0.03, 0.97, annotation_text, transform=axes[i].transAxes, fontsize=8,\n",
    "                 verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5, pad=4))\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[n:]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "fig.suptitle(f\"CEINMS vs SO Activations vs EMG - Subject: {subject}\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Single Leg Support (%)', ha='center')  \n",
    "fig.text(0.001, 0.5, 'Excitation / EMG Amplitude', va='center', rotation='vertical')  \n",
    "fig.legend(['CEINMS', 'SO', 'EMG'], loc='lower right')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Activations Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_subjects      = ['PC002','PC003', 'PC006', 'PC013'] \n",
    "td_subjects      = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026'] \n",
    "cp_trials        = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "cp_trials_left   = ['trial1_l1', 'trial2_l1', 'trial3_l1']  # for PC006\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "# EMG mappings\n",
    "emg_r = {\n",
    "    'glut_med1_r':'RGLTMED','glut_med2_r':'RGLTMED','glut_med3_r':'RGLTMED',\n",
    "    'glut_min1_r':'RGLTMED','glut_min2_r':'RGLTMED','glut_min3_r':'RGLTMED',\n",
    "    'glut_max1_r':'RGLTMED','glut_max2_r':'RGLTMED','glut_max3_r':'RGLTMED',\n",
    "    'add_brev_r':'RADDLONG','add_long_r':'RADDLONG','grac_r':'RADDLONG',\n",
    "    'bifemlh_r':'RBF','bifemsh_r':'RBF','semimem_r':'RBF','semiten_r':'RBF',\n",
    "    'tib_ant_r':'RTA','ext_dig_r':'RTA','ext_hal_r':'RTA',\n",
    "    'rect_fem_r':'RRF', 'med_gas_r':'RGM','lat_gas_r':'RGM','soleus_r':'RGM'\n",
    "}\n",
    "\n",
    "\n",
    "emg_l =  {\n",
    "    'glut_med1_l': 'LGLTMED', 'glut_med2_l': 'LGLTMED', 'glut_med3_l': 'LGLTMED',\n",
    "    'glut_min1_l': 'LGLTMED', 'glut_min2_l': 'LGLTMED', 'glut_min3_l': 'LGLTMED',\n",
    "    'glut_max1_l': 'LGLTMED', 'glut_max2_l': 'LGLTMED', 'glut_max3_l': 'LGLTMED',\n",
    "    'add_brev_l': 'LADDLONG', 'add_long_l': 'LADDLONG', 'grac_l': 'LADDLONG',\n",
    "    'bifemlh_l': 'LBF', 'bifemsh_l': 'LBF', 'semimem_l': 'LBF', 'semiten_l': 'LBF',\n",
    "    'tib_ant_l': 'LTA', 'ext_dig_l': 'LTA', 'ext_hal_l': 'LTA',\n",
    "    'rect_fem_l': 'LRF', 'med_gas_l': 'LGM', 'lat_gas_l': 'LGM', 'soleus_l': 'LGM'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for subject in cp_subjects + td_subjects:\n",
    "    # pick trials and EMG map\n",
    "    if subject == 'PC006':\n",
    "        trials, emg_map = cp_trials_left, emg_l\n",
    "    elif subject in cp_subjects:\n",
    "        trials, emg_map = cp_trials, emg_r\n",
    "    else:\n",
    "        trials, emg_map = td_crouch_trials + td_normal_trials, emg_r\n",
    "\n",
    "    for trial_name in trials:\n",
    "        act_file = simulations_dir/subject/trial_name/'ceinms'/'execution'/'Activations.sto'\n",
    "        if not act_file.exists():\n",
    "            continue\n",
    "\n",
    "        print(f\"Plotting {subject} / {trial_name} …\")\n",
    "\n",
    "        ceinms_activations = import_file(os.path.join(simulations_dir, subject, trial_name,\n",
    "                                                       'ceinms','execution','Activations.sto'))\n",
    "        so_activations     = import_file(os.path.join(simulations_dir, subject, trial_name,\n",
    "                                                       'Results_SO_and_MA','StaticOptimization_activation.sto'))\n",
    "        emg_data           = import_file(os.path.join(simulations_dir, subject, trial_name,\n",
    "                                                       'processed_emg_signals.mot'))\n",
    "\n",
    "        t0 = max(ceinms_activations.time.iloc[0],\n",
    "                 so_activations.time.iloc[0],\n",
    "                 emg_data.time.iloc[0])\n",
    "        t1 = min(ceinms_activations.time.iloc[-1],\n",
    "                 so_activations.time.iloc[-1],\n",
    "                 emg_data.time.iloc[-1])\n",
    "\n",
    "        ceinms_activations = ceinms_activations[\n",
    "            (ceinms_activations.time >= t0) & (ceinms_activations.time <= t1)\n",
    "        ].reset_index(drop=True)\n",
    "        so_activations = so_activations[\n",
    "            (so_activations.time >= t0) & (so_activations.time <= t1)\n",
    "        ].reset_index(drop=True)\n",
    "        emg_data = emg_data[\n",
    "            (emg_data.time >= t0) & (emg_data.time <= t1)\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "        ceinms_activations = ceinms_activations.iloc[3:].reset_index(drop=True)\n",
    "        so_activations     = so_activations.iloc[3:].reset_index(drop=True)\n",
    "        emg_data           = emg_data.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "        new0 = so_activations.time.iloc[0]\n",
    "        dur  = so_activations.time.iloc[-1] - new0\n",
    "        for df in (ceinms_activations, so_activations, emg_data):\n",
    "            df['time'] = 100 * (df.time - new0) / dur\n",
    "\n",
    "        valid = [m for m,ch in emg_map.items()\n",
    "                 if m in ceinms_activations.columns\n",
    "                 and m in so_activations.columns\n",
    "                 and ch in emg_data.columns]\n",
    "\n",
    "         # === Plot ===\n",
    "        n = len(valid)\n",
    "        cols, rows = 4, int(np.ceil(n / 4))\n",
    "        fig, axes = plt.subplots(rows, cols,\n",
    "                                figsize=(cols * 6, rows * 5),\n",
    "                                sharex=True, sharey=True)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, muscle in enumerate(valid):\n",
    "            ax = axes[i]\n",
    "            x = so_activations.time.values\n",
    "            y_cei = np.interp(x, ceinms_activations.time, ceinms_activations[muscle])\n",
    "            y_so  = so_activations[muscle].values\n",
    "            y_emg = np.interp(x, emg_data.time, emg_data[emg_map[muscle]])\n",
    "\n",
    "            ax.plot(x, y_cei, label='CEINMS', color='blue', linewidth=2)\n",
    "            ax.plot(x, y_so,  label='SO',     color='orange', linestyle='--', linewidth=2)\n",
    "            ax.plot(x, y_emg, label='EMG',    color='black', linewidth=1.8)\n",
    "\n",
    "            ax.set_title(muscle, fontsize=18)\n",
    "            ax.set_xlim(0, 100)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.tick_params(labelsize=14)\n",
    "\n",
    "            r_so, R2_so = compute_rmse_r2(y_emg, y_so)\n",
    "            r_ce, R2_ce = compute_rmse_r2(y_emg, y_cei)\n",
    "            txt = f\"SO: RMSE={r_so:.2f}, R²={R2_so:.2f}\\n\"\\\n",
    "                f\"CEI: RMSE={r_ce:.2f}, R²={R2_ce:.2f}\"\n",
    "            ax.text(0.03, 0.97, txt,\n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=12,\n",
    "                    va='top',\n",
    "                    bbox=dict(facecolor='white', alpha=0.7, pad=4))\n",
    "\n",
    "        # Remove unused axes\n",
    "        for ax in axes[n:]:\n",
    "            fig.delaxes(ax)\n",
    "\n",
    "        fig.suptitle(f\"CEINMS vs SO vs EMG — {subject} / {trial_name}\",\n",
    "                    fontsize=24, y=1.02)\n",
    "        fig.text(0.5, -0.01, 'Single Leg Support (%)',\n",
    "                ha='center', fontsize=18)\n",
    "        fig.text(-0.01, 0.5, 'Excitation / EMG Amplitude',\n",
    "                va='center', rotation='vertical', fontsize=18)\n",
    "\n",
    "        # Bigger, centered legend\n",
    "        fig.legend(['CEINMS', 'SO', 'EMG'],\n",
    "                loc='upper center', ncol=3, fontsize=16, bbox_to_anchor=(0.5, 1.06))\n",
    "\n",
    "        plt.tight_layout(rect=[0.03, 0.03, 1, 0.98])\n",
    "\n",
    "        # Save\n",
    "        save_dir = simulations_dir / subject / trial_name / \"Activation_plots\"\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        save_path = save_dir / f\"{subject}.png\"\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"→ saved: {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare joint moments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Not normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crop all data to shared time range for joint moment comparison\n",
    "start_time = max(\n",
    "    so_force['time'].iloc[0],\n",
    "    torques['time'].iloc[0],\n",
    "    id['time'].iloc[0]\n",
    ")\n",
    "end_time = min(\n",
    "    so_force['time'].iloc[-1],\n",
    "    torques['time'].iloc[-1],\n",
    "    id['time'].iloc[-1]\n",
    ")\n",
    "\n",
    "\n",
    "so_force = crop_time(so_force, start_time, end_time)\n",
    "torques = crop_time(torques, start_time, end_time)\n",
    "inverse_dynamics = crop_time(id, start_time, end_time)\n",
    "\n",
    "\n",
    "for ma_key in moment_arms:\n",
    "    moment_arms[ma_key] = crop_time(moment_arms[ma_key], start_time, end_time)\n",
    "\n",
    "# Normalize time to percentage of single leg support \n",
    "sls_duration = end_time - start_time\n",
    "\n",
    "so_force = normalize_time(so_force, start_time, sls_duration)\n",
    "torques = normalize_time(torques, start_time, sls_duration)\n",
    "inverse_dynamics = normalize_time(inverse_dynamics, start_time, sls_duration)\n",
    "for ma_key in moment_arms:\n",
    "    moment_arms[ma_key] = normalize_time(moment_arms[ma_key], start_time, sls_duration)\n",
    "\n",
    "# Compute SO joint moments (sum force × moment arm)\n",
    "so_moments = {'time': so_force['time']}\n",
    "for joint_key in joint_suffix:\n",
    "    so_name = joint_suffix[joint_key]['so']\n",
    "    ma_df = moment_arms[so_name]\n",
    "    common_muscles = [m for m in ma_df.columns if m in so_force.columns and m != 'time']\n",
    "    moment = sum(so_force[m] * ma_df[m] for m in common_muscles)\n",
    "    so_moments[so_name] = moment.values  # ensure the moment values are arrays\n",
    "\n",
    "so_df = pd.DataFrame(so_moments)\n",
    "\n",
    "# Plot the results and compute metrics\n",
    "label_map = {\n",
    "    'hip': 'Hip flex/ext',\n",
    "    'knee': 'Knee flex/ext',\n",
    "    'ankle': 'Ankle dorsi/plantar'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, joint_key in enumerate(['hip', 'knee', 'ankle']):\n",
    "    joint_names = joint_suffix[joint_key]\n",
    "\n",
    "    # Extract columns\n",
    "    time_id = inverse_dynamics['time']\n",
    "    id_moment = inverse_dynamics[joint_names['id']]\n",
    "    \n",
    "    time_so = so_df['time']\n",
    "    so_moment = so_df[joint_names['so']]\n",
    "    \n",
    "    time_ceinms = torques['time']\n",
    "    ceinms_moment = torques[joint_names['ceinms']]\n",
    "\n",
    "    # Compute RMSE and R² (SO vs ID)\n",
    "    so_rmse, so_r2 = compute_rmse_r2_drop(id_moment, so_moment)\n",
    "    \n",
    "    # Compute RMSE and R² (CEINMS vs ID)\n",
    "    ceinms_rmse, ceinms_r2 = compute_rmse_r2_drop(id_moment, ceinms_moment)\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.plot(time_id, id_moment, label='Inverse Dynamics', color='black', linewidth=2.0)\n",
    "    ax.plot(time_so, so_moment, label='Static Optimization', color='orange', linewidth=2.0, linestyle='--')\n",
    "    ax.plot(time_ceinms, ceinms_moment, label='CEINMS', color='blue', linewidth=2.0)\n",
    "\n",
    "\n",
    "    ax.axhline(0, color='gray', linestyle='--')\n",
    "    ax.set_title(label_map[joint_key])\n",
    "    ax.set_xlim(0, 100)  # clamp x-axis to 0–100%\n",
    "    ax.set_xlabel('Single Leg Support (%)')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Moment (Nm)')\n",
    "    if i == 2:\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "    # Remove top/right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Annotate the subplot with RMSE and R²\n",
    "    annotation_text = (f\"SO: RMSE={so_rmse:.2f}, R²={so_r2:.2f}\\n\"\n",
    "                       f\"CEINMS: RMSE={ceinms_rmse:.2f}, R²={ceinms_r2:.2f}\")\n",
    "    ax.text(0.05, 0.90, annotation_text, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5, pad=5))\n",
    "\n",
    "fig.suptitle(f'Joint Moment Comparison (Leg: {leg.upper()}, Subject: {subject}, Trial: {trial_name})', fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP & NORMALISE TIME\n",
    "\n",
    "\n",
    "start_time = max(so_force['time'].iloc[0],\n",
    "                 torques['time'].iloc[0],\n",
    "                 id['time'].iloc[0])\n",
    "end_time = min(so_force['time'].iloc[-1],\n",
    "                 torques['time'].iloc[-1],\n",
    "                 id['time'].iloc[-1])\n",
    "\n",
    "so_force = crop_time(so_force, start_time, end_time)\n",
    "torques = crop_time(torques, start_time, end_time)\n",
    "inverse_dynamics = crop_time(id, start_time, end_time)\n",
    "for key in moment_arms:\n",
    "    moment_arms[key] = crop_time(moment_arms[key], start_time, end_time)\n",
    "\n",
    "# re‐normalise time to 0–100% SLS\n",
    "duration = end_time - start_time\n",
    "so_force         = normalize_time(so_force, start_time, duration)\n",
    "torques          = normalize_time(torques, start_time, duration)\n",
    "inverse_dynamics = normalize_time(inverse_dynamics, start_time, duration)\n",
    "for key in moment_arms:\n",
    "    moment_arms[key] = normalize_time(moment_arms[key], start_time, duration)\n",
    "\n",
    "\n",
    "# COMPUTE SO JOINT MOMENTS\n",
    "\n",
    "so_moments = {'time': so_force['time']}\n",
    "for joint_key, suffixes in joint_suffix.items():\n",
    "    so_col = suffixes['so']\n",
    "    ma_df  = moment_arms[so_col]\n",
    "    common = [m for m in ma_df.columns if m in so_force.columns and m!='time']\n",
    "    so_moments[so_col] = sum(so_force[m]*ma_df[m] for m in common).values\n",
    "\n",
    "so_df = pd.DataFrame(so_moments)\n",
    "\n",
    "\n",
    "# PLOT (normalised by body mass)\n",
    "\n",
    "label_map = {\n",
    "    'hip': 'Hip flex/ext',\n",
    "    'knee': 'Knee flex/ext',\n",
    "    'ankle': 'Ankle dorsi/plantar'\n",
    "}\n",
    "mass = bodymass[subject]  \n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, joint_key in enumerate(['hip','knee','ankle']):\n",
    "    so_name = joint_suffix[joint_key]['so']\n",
    "    cei_name = joint_suffix[joint_key]['ceinms']\n",
    "    id_name = joint_suffix[joint_key]['id']\n",
    "\n",
    "    # raw\n",
    "    t_id = inverse_dynamics['time']\n",
    "    m_id = inverse_dynamics[id_name] / mass\n",
    "    t_so = so_df['time']\n",
    "    m_so = so_df[so_name] / mass\n",
    "    t_cei = torques['time']\n",
    "    m_cei = torques[cei_name] / mass\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.plot(t_id,   m_id,  color='k',   lw=2, label='Inverse Dyn')\n",
    "    ax.plot(t_so,   m_so,  color='orange', ls='--', lw=2, label='SO')\n",
    "    ax.plot(t_cei,  m_cei, color='blue', lw=2, label='CEINMS')\n",
    "\n",
    "    ax.axhline(0, color='gray', ls='--')\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.set_title(label_map[joint_key])\n",
    "    ax.set_xlabel('Single Leg Support (%)')\n",
    "    if i==0:\n",
    "        ax.set_ylabel('Moment (Nm/kg)')\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    if i==2:\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "fig.suptitle(f'', fontsize=14)\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Moments (Normalised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_subjects      = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects      = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "\n",
    "\n",
    "cp_trials        = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "cp_trials_left   = ['trial1_l1', 'trial2_l1', 'trial3_l1']  \n",
    "\n",
    "# TD trials\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "# joint name bases\n",
    "joint_bases = {\n",
    "    'hip':   'hip_flexion',\n",
    "    'knee':  'knee_angle',\n",
    "    'ankle': 'ankle_angle'\n",
    "}\n",
    "\n",
    "\n",
    "# BATCH PROCESSING\n",
    "\n",
    "for subject in cp_subjects + td_subjects:\n",
    "\n",
    "    # pick the right list of trials\n",
    "    if subject in cp_subjects:\n",
    "        trials = cp_trials_left if subject == 'PC006' else cp_trials\n",
    "    else:\n",
    "        trials = td_crouch_trials + td_normal_trials\n",
    "\n",
    "    for trial_name in trials:\n",
    "        fld = simulations_dir/subject/trial_name\n",
    "        torq_fp = fld/\"ceinms\"/\"execution\"/\"Torques.sto\"\n",
    "        if not torq_fp.exists():\n",
    "            # no CEINMS torques here: skip\n",
    "            continue\n",
    "\n",
    "        print(f\"> Plotting moments for {subject} / {trial_name} …\")\n",
    "\n",
    "        # load\n",
    "        so_force   = load_sto(fld/\"Results_SO_and_MA\"/\"StaticOptimization_force.sto\")\n",
    "        ce_torques = load_sto(torq_fp)\n",
    "        idy        = load_sto(fld/\"inverse_dynamics.sto\")\n",
    "\n",
    "        # correct TD time‐scale if needed\n",
    "        if subject in td_subjects:\n",
    "            so_force   = fix_time_scale(so_force)\n",
    "            ce_torques = fix_time_scale(ce_torques)\n",
    "            idy        = fix_time_scale(idy)\n",
    "\n",
    "        # load moment arms for this side\n",
    "        side = 'l' if subject=='PC006' else 'r'\n",
    "        moment_arms = {}\n",
    "        for base in joint_bases.values():\n",
    "            key = f\"{base}_{side}\"\n",
    "            fp = fld/\"Results_SO_and_MA\"/f\"MuscleAnalysis_MomentArm_{key}.sto\"\n",
    "            if fp.exists():\n",
    "                moment_arms[key] = load_sto(fp)\n",
    "                if subject in td_subjects:\n",
    "                    moment_arms[key] = fix_time_scale(moment_arms[key])\n",
    "\n",
    "        # crop to common window\n",
    "        t0 = max(so_force.time.iloc[0], ce_torques.time.iloc[0], idy.time.iloc[0])\n",
    "        t1 = min(so_force.time.iloc[-1],ce_torques.time.iloc[-1],idy.time.iloc[-1])\n",
    "        so_force   = crop_time(so_force,   t0, t1)\n",
    "        ce_torques = crop_time(ce_torques, t0, t1)\n",
    "        idy        = crop_time(idy,        t0, t1)\n",
    "        for k, df_ma in list(moment_arms.items()):\n",
    "            moment_arms[k] = crop_time(df_ma, t0, t1)\n",
    "\n",
    "        # normalise time to 0–100%\n",
    "        dur = t1 - t0\n",
    "        so_force   = normalize_time(so_force,   t0, dur)\n",
    "        ce_torques = normalize_time(ce_torques, t0, dur)\n",
    "        idy        = normalize_time(idy,        t0, dur)\n",
    "        for k, df_ma in moment_arms.items():\n",
    "            moment_arms[k] = normalize_time(df_ma, t0, dur)\n",
    "\n",
    "        # re‐grid moment arms onto so_force.time\n",
    "        tg = so_force.time.values\n",
    "        for key, df_ma in moment_arms.items():\n",
    "            new = {'time': tg}\n",
    "            for c in df_ma.columns:\n",
    "                if c=='time': continue\n",
    "                new[c] = np.interp(tg, df_ma.time.values, df_ma[c].values)\n",
    "            moment_arms[key] = pd.DataFrame(new)\n",
    "\n",
    "        # compute SO moments\n",
    "        so_mom_dict = {'time': so_force.time}\n",
    "        for joint, base in joint_bases.items():\n",
    "            key = f\"{base}_{side}\"\n",
    "            if key in moment_arms:\n",
    "                df_ma = moment_arms[key]\n",
    "                common = [m for m in df_ma.columns if m!='time' and m in so_force.columns]\n",
    "                so_mom_dict[key] = sum(so_force[m]*df_ma[m] for m in common).values\n",
    "        so_mom = pd.DataFrame(so_mom_dict)\n",
    "\n",
    "       \n",
    "\n",
    "        # plot normalised by BW\n",
    "        mass = bodymass[subject]\n",
    "        fig, axes = plt.subplots(1,3,figsize=(12,4),sharex=True)\n",
    "        for i,(joint,base) in enumerate(joint_bases.items()):\n",
    "            so_col = f\"{base}_{side}\"\n",
    "            cei_col= so_col\n",
    "            id_col = f\"{base}_{side}_moment\"\n",
    "\n",
    "            t_id, m_id = idy.time,        idy[id_col]    / mass\n",
    "            t_so, m_so = so_mom.time,     so_mom[so_col] / mass\n",
    "            t_ce, m_ce = ce_torques.time, ce_torques[cei_col] / mass\n",
    "\n",
    "            # RMSE/R² computation removed\n",
    "\n",
    "            ax = axes[i]\n",
    "            ax.plot(t_id, m_id,  'k-', lw=2, label='ID')\n",
    "            ax.plot(t_so, m_so, '--', c='orange', lw=2, label='SO')\n",
    "            ax.plot(t_ce, m_ce, 'b-', lw=2, label='CEINMS')\n",
    "            ax.axhline(0, color='gray', ls='--')\n",
    "            ax.set_xlim(0,100)\n",
    "            ax.set_title(joint.capitalize())\n",
    "            ax.set_xlabel('SLS (%)')\n",
    "            if i==0:\n",
    "                ax.set_ylabel('Moment (Nm/kg)')\n",
    "            # Removed ax.text(...) that annotated RMSE and R²\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            if i==2:\n",
    "                ax.legend(loc='lower right')\n",
    "            ax.grid(False)\n",
    "\n",
    "        fig.suptitle(f\"\", fontsize=14)\n",
    "        plt.tight_layout(rect=[0,0,1,0.95])\n",
    "\n",
    "        # save into each trial folder\n",
    "        outdir = fld/\"Moment_plots\"\n",
    "        outdir.mkdir(exist_ok=True)\n",
    "        fig.savefig(outdir/f\"{subject}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\" → saved: {outdir/ (subject+'.png')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare muscle forces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject groups\n",
    "cp_subjects      = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects      = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "cp_trials        = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "# LOAD & RESAMPLE\n",
    "\n",
    "cp_data_all = []\n",
    "td_crouch_data_all = []\n",
    "td_normal_data_all = []\n",
    "\n",
    "for sub in cp_subjects:\n",
    "    if sub == 'PC006':\n",
    "        trials, mg_map = ['trial2_l1'], muscle_groups_left\n",
    "    else:\n",
    "        trials, mg_map = cp_trials, muscle_groups\n",
    "    for tr in trials:\n",
    "        fp = simulations_dir / sub / tr / 'ceinms' / 'execution' / 'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        data = {}\n",
    "        for grp, mus in mg_map.items():\n",
    "            valid = [m for m in mus if m in df.columns]\n",
    "            if valid:\n",
    "                data[grp] = resample_to_percent_phase(df[valid])\n",
    "        cp_data_all.append(data)\n",
    "\n",
    "for sub in td_subjects:\n",
    "    for tr in td_crouch_trials:\n",
    "        fp = simulations_dir / sub / tr / 'ceinms' / 'execution' / 'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        data = {}\n",
    "        for grp, mus in muscle_groups.items():\n",
    "            valid = [m for m in mus if m in df.columns]\n",
    "            if valid:\n",
    "                data[grp] = resample_to_percent_phase(df[valid])\n",
    "        td_crouch_data_all.append(data)\n",
    "\n",
    "for sub in td_subjects:\n",
    "    for tr in td_normal_trials:\n",
    "        fp = simulations_dir / sub / tr / 'ceinms' / 'execution' / 'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        data = {}\n",
    "        for grp, mus in muscle_groups.items():\n",
    "            valid = [m for m in mus if m in df.columns]\n",
    "            if valid:\n",
    "                data[grp] = resample_to_percent_phase(df[valid])\n",
    "        td_normal_data_all.append(data)\n",
    "\n",
    "# PLOTTING\n",
    "\n",
    "group_labels     = ['CP', 'TD_crouch', 'TD_normal']\n",
    "group_data_list  = [cp_data_all, td_crouch_data_all, td_normal_data_all]\n",
    "groups           = list(muscle_groups.keys())\n",
    "\n",
    "cols, rows = 2, (len(groups) + 1) // 2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 3*rows), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "legend_handles = []\n",
    "\n",
    "for idx, grp in enumerate(groups):\n",
    "    ax = axes[idx]\n",
    "    for label, data_all in zip(group_labels, group_data_list):\n",
    "        ts_list = [d[grp].mean(axis=1) for d in data_all if grp in d]\n",
    "        if not ts_list:\n",
    "            continue\n",
    "        dfc = pd.concat(ts_list, axis=1)\n",
    "        m   = dfc.mean(axis=1)\n",
    "        ci  = 1.96 * (dfc.std(axis=1) / np.sqrt(dfc.shape[1]))\n",
    "        x   = np.linspace(0, 100, len(m))\n",
    "\n",
    "        ln, = ax.plot(x, m, label=label)\n",
    "        ax.fill_between(x, m - ci, m + ci, color=ln.get_color(), alpha=0.2)\n",
    "        if label not in [h.get_label() for h in legend_handles]:\n",
    "            legend_handles.append(ln)\n",
    "\n",
    "    # y-limits: \n",
    "    if 'hip' in grp:\n",
    "        ax.set_ylim(0, 900)\n",
    "    elif 'ankle' in grp:\n",
    "        ax.set_ylim(0, 650)\n",
    "    else:\n",
    "        ax.set_ylim(0, 1700)\n",
    "\n",
    "    if grp in ('hip_flexors', 'knee_flexors', 'ankle_dorsiflexors'):\n",
    "        ax.set_yticks([])          \n",
    "        ax.set_yticklabels([])     \n",
    "\n",
    "    ax.set_title(grp.replace('_', ' ').title())\n",
    "    ax.set_xlim(0, 100)\n",
    "\n",
    "    # only ankle subplots get x-axis labels\n",
    "    if 'ankle' in grp:\n",
    "        ax.set_xlabel(\"Single Leg Support (%)\")\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # y-label only on hip extensor, knee extensor & ankle plantarflexor\n",
    "    if grp in ('hip_extensors', 'knee_extensors', 'ankle_plantarflexors'):\n",
    "        ax.set_ylabel(\"Force (N)\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# remove any unused axes\n",
    "for i in range(len(groups), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "\n",
    "# shared legend in original spot\n",
    "fig.legend(handles=legend_handles,\n",
    "           labels=[h.get_label() for h in legend_handles],\n",
    "           loc='center left', bbox_to_anchor=(1.01, 0.5),\n",
    "           frameon=False)\n",
    "\n",
    "fig.suptitle(\"Muscle Force Comparison\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cp_subjects      = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects      = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "cp_trials        = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "# LOAD & RESAMPLE\n",
    "\n",
    "cp_data_all = []\n",
    "td_crouch_data_all = []\n",
    "td_normal_data_all = []\n",
    "\n",
    "for sub in cp_subjects:\n",
    "    if sub=='PC006':\n",
    "        trials, mg_map = ['trial2_l1'], muscle_groups_left\n",
    "    else:\n",
    "        trials, mg_map = cp_trials, muscle_groups\n",
    "    for tr in trials:\n",
    "        fp = simulations_dir/sub/tr/'ceinms'/'execution'/'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        data = {}\n",
    "        for grp, mus in mg_map.items():\n",
    "            valid = [m for m in mus if m in df.columns]\n",
    "            if valid:\n",
    "                data[grp] = resample_to_percent_phase(df[valid])\n",
    "        cp_data_all.append(data)\n",
    "\n",
    "for sub in td_subjects:\n",
    "    for tr in td_crouch_trials:\n",
    "        fp = simulations_dir/sub/tr/'ceinms'/'execution'/'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp); data = {}\n",
    "        for grp,mus in muscle_groups.items():\n",
    "            valid = [m for m in mus if m in df.columns]\n",
    "            if valid: data[grp] = resample_to_percent_phase(df[valid])\n",
    "        td_crouch_data_all.append(data)\n",
    "\n",
    "for sub in td_subjects:\n",
    "    for tr in td_normal_trials:\n",
    "        fp = simulations_dir/sub/tr/'ceinms'/'execution'/'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp); data = {}\n",
    "        for grp,mus in muscle_groups.items():\n",
    "            valid = [m for m in mus if m in df.columns]\n",
    "            if valid: data[grp] = resample_to_percent_phase(df[valid])\n",
    "        td_normal_data_all.append(data)\n",
    "\n",
    "cp_mass = np.mean([bodymass[s] for s in cp_subjects])\n",
    "td_mass = np.mean([bodymass[s] for s in td_subjects])\n",
    "\n",
    "\n",
    "# PLOTTING\n",
    "\n",
    "group_labels = ['CP','TD_crouch','TD_normal']\n",
    "group_data_list = [cp_data_all,td_crouch_data_all,td_normal_data_all]\n",
    "groups = list(muscle_groups.keys())\n",
    "\n",
    "cols, rows = 2, (len(groups)+1)//2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14,3*rows), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "legend_handles = []\n",
    "\n",
    "for idx, grp in enumerate(groups):\n",
    "    ax = axes[idx]\n",
    "    for label, data_all in zip(group_labels, group_data_list):\n",
    "        ts_list = [d[grp].mean(axis=1) for d in data_all if grp in d]\n",
    "        if not ts_list: continue\n",
    "        dfc = pd.concat(ts_list, axis=1)\n",
    "        m   = dfc.mean(axis=1)\n",
    "        ci  = 1.96*(dfc.std(axis=1)/np.sqrt(dfc.shape[1]))\n",
    "        if label=='CP':\n",
    "            m  /= cp_mass; ci /= cp_mass\n",
    "        else:\n",
    "            m  /= td_mass; ci /= td_mass\n",
    "        x = np.linspace(0,100,len(m))\n",
    "        ln, = ax.plot(x,m,label=label)\n",
    "        ax.fill_between(x, m-ci, m+ci, color=ln.get_color(), alpha=0.2)\n",
    "        if label not in [h.get_label() for h in legend_handles]:\n",
    "            legend_handles.append(ln)\n",
    "\n",
    "    # y‑limits\n",
    "    if 'hip' in grp:\n",
    "        ax.set_ylim(0,22)\n",
    "    elif 'knee' in grp:\n",
    "        ax.set_ylim(0,45)\n",
    "    else:\n",
    "        ax.set_ylim(0,17)\n",
    "\n",
    "    if grp in ('hip_flexors', 'knee_flexors', 'ankle_dorsiflexors'):\n",
    "        ax.set_yticks([])          \n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    ax.set_title(grp.replace('_',' ').title())\n",
    "    ax.set_xlim(0,100)\n",
    "\n",
    "    # only ankle get x‑axis labels\n",
    "    if 'ankle' in grp:\n",
    "        ax.set_xlabel(\"Single Leg Support (%)\")\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # y‑label only for extensors + plantarflexors\n",
    "    if grp in ('hip_extensors','ankle_plantarflexors', 'knee_extensors'):\n",
    "        ax.set_ylabel(\"Force (N/kg)\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# hide extras\n",
    "for i in range(len(groups),len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# shared legend back to original spot\n",
    "fig.legend(handles=legend_handles,\n",
    "           labels=[h.get_label() for h in legend_handles],\n",
    "           loc='center left',\n",
    "           bbox_to_anchor=(1.01,0.5),\n",
    "           frameon=False)\n",
    "\n",
    "fig.suptitle(\"Muscle Force Comparison (Normalised to Body‐Mass)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muscle force plots only for CP children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_subjects      = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects      = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "td_crouch_trials = ['crouch1_r1','crouch2_r1','crouch3_r1']\n",
    "\n",
    "\n",
    "# average TD mass\n",
    "td_mass = np.mean([bodymass[s] for s in td_subjects])\n",
    "\n",
    "# LOAD\n",
    "\n",
    "all_trials = []   # list of (subject, data_dict)\n",
    "td_crouch_trials_data = []  # list of data_dict only\n",
    "\n",
    "# CP subjects\n",
    "for sub in cp_subjects:\n",
    "    if sub=='PC006':\n",
    "        trials, mg = ['trial2_l1'], muscle_groups_left\n",
    "    else:\n",
    "        trials, mg = cp_trials, muscle_groups\n",
    "    for tr in trials:\n",
    "        fp = simulations_dir/sub/tr/'ceinms'/'execution'/'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        d = {}\n",
    "        for grp, cols in mg.items():\n",
    "            valid = [m for m in cols if m in df.columns]\n",
    "            if valid:\n",
    "                d[grp] = resample_to_percent_phase(df[valid])\n",
    "        all_trials.append((sub, d))\n",
    "\n",
    "# TD crouch\n",
    "for sub in td_subjects:\n",
    "    for tr in td_crouch_trials:\n",
    "        fp = simulations_dir/sub/tr/'ceinms'/'execution'/'MuscleForces.sto'\n",
    "        if not fp.exists(): continue\n",
    "        df = load_sto(fp)\n",
    "        d = {}\n",
    "        for grp, cols in muscle_groups.items():\n",
    "            valid = [m for m in cols if m in df.columns]\n",
    "            if valid:\n",
    "                d[grp] = resample_to_percent_phase(df[valid])\n",
    "        td_crouch_trials_data.append(d)\n",
    "\n",
    "\n",
    "# PLOTTING (normalised to BW)\n",
    "\n",
    "colors = {'PC002':'tab:blue','PC003':'tab:purple','PC006':'tab:olive','PC013':'tab:red'}\n",
    "groups = list(muscle_groups.keys())\n",
    "cols, rows = 2, (len(groups)+1)//2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14,3*rows), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "legend_labels = {}\n",
    "\n",
    "for idx,(grp_r, grp_l) in enumerate(zip(muscle_groups.keys(), muscle_groups_left.keys())):\n",
    "    ax = axes[idx]\n",
    "    # CP individuals (normalised by each child's BW)\n",
    "    for sub, d in all_trials:\n",
    "        key = grp_l if sub=='PC006' else grp_r\n",
    "        if key not in d: continue\n",
    "        ts = d[key].mean(axis=1)/bodymass[sub]\n",
    "        x  = np.linspace(0,100,len(ts))\n",
    "        lbl= sub if sub not in legend_labels else None\n",
    "        ln = ax.plot(x,ts,color=colors[sub],label=lbl)[0]\n",
    "        legend_labels[sub] = colors[sub]\n",
    "    # TD crouch mean+CI (normalised by average TD BW)\n",
    "    series_list = [d[grp_r].mean(axis=1)/td_mass for d in td_crouch_trials_data if grp_r in d]\n",
    "    if series_list:\n",
    "        dfc = pd.concat(series_list,axis=1)\n",
    "        m   = dfc.mean(axis=1)\n",
    "        ci  = 1.96*(dfc.std(axis=1)/np.sqrt(dfc.shape[1]))\n",
    "        x   = np.linspace(0,100,len(m))\n",
    "        ax.fill_between(x, m-ci, m+ci, color='tab:orange',alpha=0.15)\n",
    "        ln = ax.plot(x,m, color='tab:orange',label='TD crouch mean')[0]\n",
    "        legend_labels['TD crouch'] = 'tab:orange'\n",
    "\n",
    "    # y‑limits and labels\n",
    "    if 'hip' in grp_r:\n",
    "        ax.set_ylim(0,17)\n",
    "    elif 'knee' in grp_r:\n",
    "        ax.set_ylim(0,34)\n",
    "    else:\n",
    "        ax.set_ylim(0,27)\n",
    "\n",
    "    if grp_r in ('hip_flexors', 'knee_flexors', 'ankle_dorsiflexors'):\n",
    "        ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "    ax.set_xlim(0,100)\n",
    "    ax.set_title(grp_r.replace('_',' ').title())\n",
    "    if 'ankle' in grp_r:\n",
    "        ax.set_xlabel(\"Single Leg Support (%)\")\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if grp_r in ('hip_extensors','ankle_plantarflexors', 'knee_extensors'):\n",
    "        ax.set_ylabel(\"Force (N/kg)\")\n",
    "\n",
    "    \n",
    "# hide extras\n",
    "for i in range(len(groups),len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# legend back in the plantarflexors plot\n",
    "handles = [plt.Line2D([0],[0],color=clr,lw=2) for lbl,clr in legend_labels.items()]\n",
    "labels  = list(legend_labels.keys())\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.01,0.5), frameon=False)\n",
    "\n",
    "fig.suptitle(\"Individual Muscle Forces – CP & TD Crouch (Normalised to BW)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average muscle forces (bar chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_subjects      = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects      = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "\n",
    "cp_trials        = ['trial1_r1','trial2_r1','trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1','crouch2_r1','crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1','normal2_r1','normal3_r1']\n",
    "\n",
    "# Load data\n",
    "\n",
    "# CP\n",
    "cp_data = {}\n",
    "for s in cp_subjects:\n",
    "    if s=='PC006':\n",
    "        cp_data[s] = gather_data([s], ['trial2_l1'], muscle_groups_left)[s]\n",
    "    else:\n",
    "        cp_data[s] = gather_data([s], cp_trials, muscle_groups)[s]\n",
    "\n",
    "# TD crouch & TD normal\n",
    "td_c_data = gather_data(td_subjects, td_crouch_trials, muscle_groups)\n",
    "td_n_data = gather_data(td_subjects, td_normal_trials, muscle_groups)\n",
    "\n",
    "\n",
    "# Compute per‐subject mean force per group (over time & trials), normalised by mass\n",
    "\n",
    "groups = list(muscle_groups.keys())\n",
    "\n",
    "# CP individuals\n",
    "cp_means = {}\n",
    "for s, trials in cp_data.items():\n",
    "    subj_vals = {}\n",
    "    for grp in groups:\n",
    "        # mean over time & trials\n",
    "        vals = [t[grp].mean(axis=1).mean() for t in trials if grp in t]\n",
    "        subj_vals[grp] = np.mean(vals)/bodymass[s] if vals else np.nan\n",
    "    cp_means[s] = subj_vals\n",
    "\n",
    "# TD group (per‐subject, then across subjects)\n",
    "tdc_subj = {s: {} for s in td_subjects}\n",
    "tdn_subj = {s: {} for s in td_subjects}\n",
    "for s in td_subjects:\n",
    "    # crouch\n",
    "    vals_c = [t[grp].mean(axis=1).mean() for t in td_c_data[s] if grp in t]\n",
    "    # normal\n",
    "    vals_n = [t[grp].mean(axis=1).mean() for t in td_n_data[s] if grp in t]\n",
    "    # store normalised\n",
    "    for grp in groups:\n",
    "        c_vals = [\n",
    "            d[grp].mean(axis=1).mean() \n",
    "            for d in td_c_data[s] if grp in d\n",
    "        ]\n",
    "        n_vals = [\n",
    "            d[grp].mean(axis=1).mean() \n",
    "            for d in td_n_data[s] if grp in d\n",
    "        ]\n",
    "        tdc_subj[s][grp] = np.mean(c_vals)/bodymass[s] if c_vals else np.nan\n",
    "        tdn_subj[s][grp] = np.mean(n_vals)/bodymass[s] if n_vals else np.nan\n",
    "\n",
    "# now group‐mean ± SEM across subjects\n",
    "def group_stats(subj_dict):\n",
    "    mean = np.array([ [subj_dict[s][g] for g in groups] for s in subj_dict ])\n",
    "    gm   = np.nanmean(mean, axis=0)\n",
    "    sem  = np.nanstd(mean, axis=0, ddof=1) / np.sqrt(len(subj_dict))\n",
    "    return gm, sem\n",
    "\n",
    "tdc_mean, tdc_sem = group_stats(tdc_subj)\n",
    "tdn_mean, tdn_sem = group_stats(tdn_subj)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "\n",
    "x = np.arange(len(groups))\n",
    "categories = ['TD Crouch','TD Normal'] + cp_subjects\n",
    "colors = {'TD Crouch':'tab:orange','TD Normal':'tab:green',\n",
    "              'PC002':'tab:blue','PC003':'tab:purple','PC006':'tab:olive','PC013':'tab:red'}\n",
    "n_cats = len(categories)\n",
    "width = 0.8 / n_cats\n",
    "offset = np.arange(n_cats)*width - 0.4 + width/2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "for j, cat in enumerate(categories):\n",
    "    xs = x + offset[j]\n",
    "    if cat=='TD Crouch':\n",
    "        ax.bar(xs, tdc_mean, width,\n",
    "               yerr=tdc_sem, capsize=4,\n",
    "               color=colors[cat], label=cat)\n",
    "    elif cat=='TD Normal':\n",
    "        ax.bar(xs, tdn_mean, width,\n",
    "               yerr=tdn_sem, capsize=4,\n",
    "               color=colors[cat], label=cat)\n",
    "    else:\n",
    "        y = [cp_means[cat][g] for g in groups]\n",
    "        ax.bar(xs, y, width,\n",
    "               color=colors[cat], edgecolor='k',\n",
    "               label=cat)\n",
    "\n",
    "# labels & formatting\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(groups, rotation=45, ha='right')\n",
    "ax.set_ylabel('Force (N/kg)')\n",
    "ax.set_title('Muscle Forces (N/kg): TD Crouch vs TD Normal + CP Individuals')\n",
    "\n",
    "# legend to the right, as before\n",
    "ax.legend(ncol=2, bbox_to_anchor=(1.02,1), loc='upper left', frameon=False)\n",
    "\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating RMSE and R squared for muscle activations and joint moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_subjects = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "\n",
    "cp_trials        = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "group_trials = {\n",
    "    'CP':        [(s, t) for s in cp_subjects for t in cp_trials],\n",
    "    'TD_crouch': [(s, t) for s in td_subjects for t in td_crouch_trials],\n",
    "    'TD_normal': [(s, t) for s in td_subjects for t in td_normal_trials]\n",
    "}\n",
    "\n",
    "emg_mappings = {\n",
    "    'glut_med1_r':'RGLTMED','glut_med2_r':'RGLTMED','glut_med3_r':'RGLTMED',\n",
    "    'glut_min1_r':'RGLTMED','glut_min2_r':'RGLTMED','glut_min3_r':'RGLTMED',\n",
    "    'glut_max1_r':'RGLTMED','glut_max2_r':'RGLTMED','glut_max3_r':'RGLTMED',\n",
    "    'add_brev_r':'RADDLONG','add_long_r':'RADDLONG','grac_r':'RADDLONG',\n",
    "    'bifemlh_r':'RBF','bifemsh_r':'RBF','semimem_r':'RBF','semiten_r':'RBF',\n",
    "    'tib_ant_r':'RTA','ext_dig_r':'RTA','ext_hal_r':'RTA',\n",
    "    'vas_med_r':'RRF','vas_int_r':'RRF','vas_lat_r':'RRF','rect_fem_r':'RRF',\n",
    "    'med_gas_r':'RGM','lat_gas_r':'RGM','soleus_r':'RGM'\n",
    "}\n",
    "\n",
    "joint_suffix = {\n",
    "    'hip':   {'so':'hip_flexion_r','ceinms':'hip_flexion_r','id':'hip_flexion_r_moment'},\n",
    "    'knee':  {'so':'knee_angle_r', 'ceinms':'knee_angle_r', 'id':'knee_angle_r_moment'},\n",
    "    'ankle': {'so':'ankle_angle_r','ceinms':'ankle_angle_r','id':'ankle_angle_r_moment'}\n",
    "}\n",
    "\n",
    "\n",
    "# PROCESS ONE TRIAL\n",
    "\n",
    "def process_trial(subj, trial):\n",
    "    fld = simulations_dir/subj/trial\n",
    "\n",
    "    #  activations \n",
    "    so_p = fld/\"Results_SO_and_MA\"/\"StaticOptimization_activation.sto\"\n",
    "    ce_p = fld/\"ceinms\"/\"execution\"/\"Activations.sto\"\n",
    "    emg_p= fld/\"processed_emg_signals.mot\"\n",
    "    if not (so_p.exists() and ce_p.exists() and emg_p.exists()):\n",
    "        return None\n",
    "\n",
    "    so_act = load_sto(so_p); ce_act = load_sto(ce_p); emg = load_sto(emg_p)\n",
    "    if subj in td_subjects:\n",
    "        so_act = fix_time_scale(so_act)\n",
    "        ce_act = fix_time_scale(ce_act)\n",
    "        emg    = fix_time_scale(emg)\n",
    "\n",
    "    t0 = max(so_act.time.iloc[0], ce_act.time.iloc[0], emg.time.iloc[0])\n",
    "    t1 = min(so_act.time.iloc[-1], ce_act.time.iloc[-1], emg.time.iloc[-1])\n",
    "    so_act = crop_time(so_act,t0,t1)\n",
    "    ce_act = crop_time(ce_act,t0,t1)\n",
    "    emg    = crop_time(emg,   t0,t1)\n",
    "\n",
    "    so_rm, so_r2, ce_rm, ce_r2 = [],[],[],[]\n",
    "    for m,ch in emg_mappings.items():\n",
    "        if m in so_act.columns and ch in emg.columns:\n",
    "            r0,r1 = compute_rmse_r2_drop(emg[ch], so_act[m])\n",
    "            so_rm.append(r0); so_r2.append(r1)\n",
    "        if m in ce_act.columns and ch in emg.columns:\n",
    "            r0,r1 = compute_rmse_r2_drop(emg[ch], ce_act[m])\n",
    "            ce_rm.append(r0); ce_r2.append(r1)\n",
    "\n",
    "    # joint moments \n",
    "    sof_p = fld/\"Results_SO_and_MA\"/\"StaticOptimization_force.sto\"\n",
    "    cet_p = fld/\"ceinms\"/\"execution\"/\"Torques.sto\"\n",
    "    idy_p = fld/\"inverse_dynamics.sto\"\n",
    "    if not (sof_p.exists() and cet_p.exists() and idy_p.exists()):\n",
    "        return None\n",
    "\n",
    "    sof = load_sto(sof_p); cet = load_sto(cet_p); idy = load_sto(idy_p)\n",
    "    if subj in td_subjects:\n",
    "        sof = fix_time_scale(sof)\n",
    "        cet = fix_time_scale(cet)\n",
    "        idy = fix_time_scale(idy)\n",
    "\n",
    "    # load moment arms\n",
    "    ma = {}\n",
    "    for j,suf in joint_suffix.items():\n",
    "        fp = fld/\"Results_SO_and_MA\"/f\"MuscleAnalysis_MomentArm_{suf['so']}.sto\"\n",
    "        if fp.exists():\n",
    "            ma[suf['so']] = load_sto(fp)\n",
    "\n",
    "    t2 = max(sof.time.iloc[0], cet.time.iloc[0], idy.time.iloc[0])\n",
    "    t3 = min(sof.time.iloc[-1],cet.time.iloc[-1],idy.time.iloc[-1])\n",
    "    sof = crop_time(sof,t2,t3)\n",
    "    cet = crop_time(cet,t2,t3)\n",
    "    idy = crop_time(idy,t2,t3)\n",
    "    for k in ma:\n",
    "        ma[k] = crop_time(ma[k],t2,t3)\n",
    "\n",
    "    dur = t3 - t2\n",
    "    sof = normalize_time(sof,t2,dur)\n",
    "    cet = normalize_time(cet,t2,dur)\n",
    "    idy = normalize_time(idy,t2,dur)\n",
    "    for k in ma:\n",
    "        ma[k] = normalize_time(ma[k],t2,dur)\n",
    "\n",
    "    so_j = compute_so_joint_moments(sof, ma, joint_suffix)\n",
    "\n",
    "    so_j_rm, so_j_r2, ce_j_rm, ce_j_r2 = [],[],[],[]\n",
    "    for j,suf in joint_suffix.items():\n",
    "        if suf['so'] in so_j.columns and suf['id'] in idy.columns:\n",
    "            r0,r1 = compute_rmse_r2_drop(idy[suf['id']], so_j[suf['so']])\n",
    "            so_j_rm.append(r0); so_j_r2.append(r1)\n",
    "        if suf['ceinms'] in cet.columns and suf['id'] in idy.columns:\n",
    "            r0,r1 = compute_rmse_r2_drop(idy[suf['id']], cet[suf['ceinms']])\n",
    "            ce_j_rm.append(r0); ce_j_r2.append(r1)\n",
    "\n",
    "    return {\n",
    "        \"so_activation_rmse\":      np.nanmean(so_rm),\n",
    "        \"so_activation_r2\":        np.nanmean(so_r2),\n",
    "        \"ceinms_activation_rmse\":  np.nanmean(ce_rm),\n",
    "        \"ceinms_activation_r2\":    np.nanmean(ce_r2),\n",
    "        \"so_moments_rmse\":         np.nanmean(so_j_rm),\n",
    "        \"so_moments_r2\":           np.nanmean(so_j_r2),\n",
    "        \"ceinms_moments_rmse\":     np.nanmean(ce_j_rm),\n",
    "        \"ceinms_moments_r2\":       np.nanmean(ce_j_r2)\n",
    "    }\n",
    "\n",
    "\n",
    "# RUN & AGGREGATE\n",
    "\n",
    "group_results = {g: [] for g in group_trials}\n",
    "for g, trials in group_trials.items():\n",
    "    for subj, tr in trials:\n",
    "        res = process_trial(subj, tr)\n",
    "        if res:\n",
    "            group_results[g].append(res)\n",
    "\n",
    "# Aggregate into DataFrame and compute means and SDs:\n",
    "final = []\n",
    "for g, lst in group_results.items():\n",
    "    if not lst:\n",
    "        # no data\n",
    "        final.append({\"Group\": g, **{m: np.nan for m in [\n",
    "            \"SO_Activ_RMSE\",\"SO_Activ_R2\",\"CEINMS_Activ_RMSE\",\"CEINMS_Activ_R2\",\n",
    "            \"SO_Mom_RMSE\",\"SO_Mom_R2\",\"CEINMS_Mom_RMSE\",\"CEINMS_Mom_R2\"\n",
    "        ]}})\n",
    "        continue\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    means = df.mean()\n",
    "    sds   = df.std()\n",
    "\n",
    "    final.append({\n",
    "        \"Group\": g,\n",
    "        \"SO_Activ_RMSE\":        f\"{means['so_activation_rmse']:.4f} ± {sds['so_activation_rmse']:.4f}\",\n",
    "        \"SO_Activ_R2\":          f\"{means['so_activation_r2']:.4f} ± {sds['so_activation_r2']:.4f}\",\n",
    "        \"CEINMS_Activ_RMSE\":    f\"{means['ceinms_activation_rmse']:.4f} ± {sds['ceinms_activation_rmse']:.4f}\",\n",
    "        \"CEINMS_Activ_R2\":      f\"{means['ceinms_activation_r2']:.4f} ± {sds['ceinms_activation_r2']:.4f}\",\n",
    "        \"SO_Mom_RMSE\":          f\"{means['so_moments_rmse']:.4f} ± {sds['so_moments_rmse']:.4f}\",\n",
    "        \"SO_Mom_R2\":            f\"{means['so_moments_r2']:.4f} ± {sds['so_moments_r2']:.4f}\",\n",
    "        \"CEINMS_Mom_RMSE\":      f\"{means['ceinms_moments_rmse']:.4f} ± {sds['ceinms_moments_rmse']:.4f}\",\n",
    "        \"CEINMS_Mom_R2\":        f\"{means['ceinms_moments_r2']:.4f} ± {sds['ceinms_moments_r2']:.4f}\",\n",
    "    })\n",
    "\n",
    "df_final = pd.DataFrame(final)\n",
    "\n",
    "\n",
    "# Render as a nice table\n",
    "fig, ax = plt.subplots(figsize=(14, 2))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# header + rows\n",
    "cols = df_final.columns.tolist()\n",
    "table_data = [cols]\n",
    "for row in df_final.itertuples(index=False):\n",
    "    table_data.append(list(row))\n",
    "\n",
    "tbl = ax.table(\n",
    "    cellText=table_data,\n",
    "    cellLoc=\"center\",\n",
    "    colLabels=None,\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(8)\n",
    "for c in range(len(cols)):\n",
    "    tbl.auto_set_column_width(c)\n",
    "\n",
    "plt.title(\"RMSE, R² and Relative Std Dev (RSD) Across Groups\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised to the bodyweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trial(subj, trial):\n",
    "    fld = simulations_dir / subj / trial\n",
    "\n",
    "    # — activations —\n",
    "    so_p = fld / \"Results_SO_and_MA\" / \"StaticOptimization_activation.sto\"\n",
    "    ce_p = fld / \"ceinms\" / \"execution\" / \"Activations.sto\"\n",
    "    emg_p = fld / \"processed_emg_signals.mot\"\n",
    "    if not (so_p.exists() and ce_p.exists() and emg_p.exists()):\n",
    "        return None\n",
    "\n",
    "    so_act = load_sto(so_p); ce_act = load_sto(ce_p); emg = load_sto(emg_p)\n",
    "    if subj in td_subjects:\n",
    "        so_act = fix_time_scale(so_act)\n",
    "        ce_act = fix_time_scale(ce_act)\n",
    "        emg = fix_time_scale(emg)\n",
    "\n",
    "    t0 = max(so_act.time.iloc[0], ce_act.time.iloc[0], emg.time.iloc[0])\n",
    "    t1 = min(so_act.time.iloc[-1], ce_act.time.iloc[-1], emg.time.iloc[-1])\n",
    "    so_act = crop_time(so_act, t0, t1)\n",
    "    ce_act = crop_time(ce_act, t0, t1)\n",
    "    emg = crop_time(emg, t0, t1)\n",
    "\n",
    "    so_rm, so_r2, ce_rm, ce_r2 = [], [], [], []\n",
    "    for m, ch in emg_mappings.items():\n",
    "        if m in so_act.columns and ch in emg.columns:\n",
    "            r0, r1 = compute_rmse_r2_drop(emg[ch], so_act[m])\n",
    "            so_rm.append(r0); so_r2.append(r1)\n",
    "        if m in ce_act.columns and ch in emg.columns:\n",
    "            r0, r1 = compute_rmse_r2_drop(emg[ch], ce_act[m])\n",
    "            ce_rm.append(r0); ce_r2.append(r1)\n",
    "\n",
    "    # — joint moments —\n",
    "    sof_p = fld / \"Results_SO_and_MA\" / \"StaticOptimization_force.sto\"\n",
    "    cet_p = fld / \"ceinms\" / \"execution\" / \"Torques.sto\"\n",
    "    idy_p = fld / \"inverse_dynamics.sto\"\n",
    "    if not (sof_p.exists() and cet_p.exists() and idy_p.exists()):\n",
    "        return None\n",
    "\n",
    "    sof = load_sto(sof_p); cet = load_sto(cet_p); idy = load_sto(idy_p)\n",
    "    if subj in td_subjects:\n",
    "        sof = fix_time_scale(sof)\n",
    "        cet = fix_time_scale(cet)\n",
    "        idy = fix_time_scale(idy)\n",
    "\n",
    "    # load moment arms\n",
    "    ma = {}\n",
    "    for j, suf in joint_suffix.items():\n",
    "        fp = fld / \"Results_SO_and_MA\" / f\"MuscleAnalysis_MomentArm_{suf['so']}.sto\"\n",
    "        if fp.exists():\n",
    "            ma[suf['so']] = load_sto(fp)\n",
    "\n",
    "    t2 = max(sof.time.iloc[0], cet.time.iloc[0], idy.time.iloc[0])\n",
    "    t3 = min(sof.time.iloc[-1], cet.time.iloc[-1], idy.time.iloc[-1])\n",
    "    sof = crop_time(sof, t2, t3)\n",
    "    cet = crop_time(cet, t2, t3)\n",
    "    idy = crop_time(idy, t2, t3)\n",
    "    for k in ma:\n",
    "        ma[k] = crop_time(ma[k], t2, t3)\n",
    "\n",
    "    dur = t3 - t2\n",
    "    sof = normalize_time(sof, t2, dur)\n",
    "    cet = normalize_time(cet, t2, dur)\n",
    "    idy = normalize_time(idy, t2, dur)\n",
    "    for k in ma:\n",
    "        ma[k] = normalize_time(ma[k], t2, dur)\n",
    "\n",
    "    so_j = compute_so_joint_moments(sof, ma, joint_suffix)\n",
    "\n",
    "    bm = bodymass[subj]\n",
    "    so_j_rm, so_j_r2, ce_j_rm, ce_j_r2 = [], [], [], []\n",
    "    for j, suf in joint_suffix.items():\n",
    "        if suf['so'] in so_j.columns and suf['id'] in idy.columns:\n",
    "            idy_norm = idy[suf['id']] / bm\n",
    "            soj_norm = so_j[suf['so']] / bm\n",
    "            r0, r1 = compute_rmse_r2_drop(idy_norm, soj_norm)\n",
    "            so_j_rm.append(r0); so_j_r2.append(r1)\n",
    "        if suf['ceinms'] in cet.columns and suf['id'] in idy.columns:\n",
    "            idy_norm = idy[suf['id']] / bm\n",
    "            ceinms_norm = cet[suf['ceinms']] / bm\n",
    "            r0, r1 = compute_rmse_r2_drop(idy_norm, ceinms_norm)\n",
    "            ce_j_rm.append(r0); ce_j_r2.append(r1)\n",
    "\n",
    "    return {\n",
    "        \"so_activation_rmse\":      np.nanmean(so_rm),\n",
    "        \"so_activation_r2\":        np.nanmean(so_r2),\n",
    "        \"ceinms_activation_rmse\":  np.nanmean(ce_rm),\n",
    "        \"ceinms_activation_r2\":    np.nanmean(ce_r2),\n",
    "        \"so_moments_rmse\":         np.nanmean(so_j_rm),\n",
    "        \"so_moments_r2\":           np.nanmean(so_j_r2),\n",
    "        \"ceinms_moments_rmse\":     np.nanmean(ce_j_rm),\n",
    "        \"ceinms_moments_r2\":       np.nanmean(ce_j_r2)\n",
    "    }\n",
    "\n",
    "cp_subjects = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "\n",
    "cp_trials        = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "group_trials = {\n",
    "    'CP':        [(s, t) for s in cp_subjects for t in cp_trials],\n",
    "    'TD_crouch': [(s, t) for s in td_subjects for t in td_crouch_trials],\n",
    "    'TD_normal': [(s, t) for s in td_subjects for t in td_normal_trials]\n",
    "}\n",
    "\n",
    "emg_mappings = {\n",
    "    'glut_med1_r':'RGLTMED','glut_med2_r':'RGLTMED','glut_med3_r':'RGLTMED',\n",
    "    'glut_min1_r':'RGLTMED','glut_min2_r':'RGLTMED','glut_min3_r':'RGLTMED',\n",
    "    'glut_max1_r':'RGLTMED','glut_max2_r':'RGLTMED','glut_max3_r':'RGLTMED',\n",
    "    'add_brev_r':'RADDLONG','add_long_r':'RADDLONG','grac_r':'RADDLONG',\n",
    "    'bifemlh_r':'RBF','bifemsh_r':'RBF','semimem_r':'RBF','semiten_r':'RBF',\n",
    "    'tib_ant_r':'RTA','ext_dig_r':'RTA','ext_hal_r':'RTA',\n",
    "    'vas_med_r':'RRF','vas_int_r':'RRF','vas_lat_r':'RRF','rect_fem_r':'RRF',\n",
    "    'med_gas_r':'RGM','lat_gas_r':'RGM','soleus_r':'RGM'\n",
    "}\n",
    "\n",
    "joint_suffix = {\n",
    "    'hip':   {'so':'hip_flexion_r','ceinms':'hip_flexion_r','id':'hip_flexion_r_moment'},\n",
    "    'knee':  {'so':'knee_angle_r', 'ceinms':'knee_angle_r', 'id':'knee_angle_r_moment'},\n",
    "    'ankle': {'so':'ankle_angle_r','ceinms':'ankle_angle_r','id':'ankle_angle_r_moment'}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# RUN & AGGREGATE\n",
    "\n",
    "group_results = {g: [] for g in group_trials}\n",
    "for g, trials in group_trials.items():\n",
    "    for subj, tr in trials:\n",
    "        res = process_trial(subj, tr)\n",
    "        if res:\n",
    "            group_results[g].append(res)\n",
    "\n",
    "# Aggregate into DataFrame and compute means and SDs:\n",
    "final = []\n",
    "for g, lst in group_results.items():\n",
    "    if not lst:\n",
    "        # no data\n",
    "        final.append({\"Group\": g, **{m: np.nan for m in [\n",
    "            \"SO_Activ_RMSE\",\"SO_Activ_R2\",\"CEINMS_Activ_RMSE\",\"CEINMS_Activ_R2\",\n",
    "            \"SO_Mom_RMSE\",\"SO_Mom_R2\",\"CEINMS_Mom_RMSE\",\"CEINMS_Mom_R2\"\n",
    "        ]}})\n",
    "        continue\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    means = df.mean()\n",
    "    sds   = df.std()\n",
    "\n",
    "    final.append({\n",
    "        \"Group\": g,\n",
    "        \"SO_Activ_RMSE\":        f\"{means['so_activation_rmse']:.4f} ± {sds['so_activation_rmse']:.4f}\",\n",
    "        \"SO_Activ_R2\":          f\"{means['so_activation_r2']:.4f} ± {sds['so_activation_r2']:.4f}\",\n",
    "        \"CEINMS_Activ_RMSE\":    f\"{means['ceinms_activation_rmse']:.4f} ± {sds['ceinms_activation_rmse']:.4f}\",\n",
    "        \"CEINMS_Activ_R2\":      f\"{means['ceinms_activation_r2']:.4f} ± {sds['ceinms_activation_r2']:.4f}\",\n",
    "        \"SO_Mom_RMSE\":          f\"{means['so_moments_rmse']:.4f} ± {sds['so_moments_rmse']:.4f}\",\n",
    "        \"SO_Mom_R2\":            f\"{means['so_moments_r2']:.4f} ± {sds['so_moments_r2']:.4f}\",\n",
    "        \"CEINMS_Mom_RMSE\":      f\"{means['ceinms_moments_rmse']:.4f} ± {sds['ceinms_moments_rmse']:.4f}\",\n",
    "        \"CEINMS_Mom_R2\":        f\"{means['ceinms_moments_r2']:.4f} ± {sds['ceinms_moments_r2']:.4f}\",\n",
    "    })\n",
    "\n",
    "df_final = pd.DataFrame(final)\n",
    "\n",
    "\n",
    "# Render as a nice table\n",
    "fig, ax = plt.subplots(figsize=(14, 2))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# header + rows\n",
    "cols = df_final.columns.tolist()\n",
    "table_data = [cols]\n",
    "for row in df_final.itertuples(index=False):\n",
    "    table_data.append(list(row))\n",
    "\n",
    "tbl = ax.table(\n",
    "    cellText=table_data,\n",
    "    cellLoc=\"center\",\n",
    "    colLabels=None,\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(8)\n",
    "for c in range(len(cols)):\n",
    "    tbl.auto_set_column_width(c)\n",
    "\n",
    "plt.title(\"RMSE, R² and Relative Std Dev (RSD) Across Groups\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare calibrated and uncalibrated ceinms models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_model = os.path.join(simulations_dir, \"PC013\", \"trial3_l1\", \"ceinms\", \"uncalibratedSubject.xml\")\n",
    "cal_model = uncal_model.replace('uncalibratedSubject.xml', 'calibratedSubject.xml')\n",
    "\n",
    "# open both xmls and compare each mtu\n",
    "ucal_model_xml = msk.bops.XMLTools().load(uncal_model)\n",
    "cal_model_xml = msk.bops.XMLTools().load(cal_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the root elements of the XML trees\n",
    "cal_root = cal_model_xml.getroot()\n",
    "ucal_root = ucal_model_xml.getroot()\n",
    "\n",
    "# Find all \"mtu\" elements in both models\n",
    "cal_mtu_elements = cal_root.findall(\".//mtu\")\n",
    "ucal_mtu_elements = ucal_root.findall(\".//mtu\")\n",
    "\n",
    "# Create dictionaries for easy lookup by muscle name\n",
    "cal_mtu_dict = {mtu.find(\"name\").text: mtu for mtu in cal_mtu_elements}\n",
    "ucal_mtu_dict = {mtu.find(\"name\").text: mtu for mtu in ucal_mtu_elements}\n",
    "\n",
    "# Loop through all muscles and compare \"maxIsometricForce\" and \"tendonSlackLength\"\n",
    "comparison_results = []\n",
    "for muscle_name, cal_mtu in cal_mtu_dict.items():\n",
    "    if muscle_name in ucal_mtu_dict:\n",
    "        ucal_mtu = ucal_mtu_dict[muscle_name]\n",
    "        \n",
    "        # Extract values for comparison\n",
    "        cal_max_iso_force = float(cal_mtu.find(\"maxIsometricForce\").text)\n",
    "        ucal_max_iso_force = float(ucal_mtu.find(\"maxIsometricForce\").text)\n",
    "        \n",
    "        cal_tendon_slack_length = float(cal_mtu.find(\"tendonSlackLength\").text)\n",
    "        ucal_tendon_slack_length = float(ucal_mtu.find(\"tendonSlackLength\").text)\n",
    "        \n",
    "        # Store the comparison results\n",
    "        comparison_results.append({\n",
    "            \"Muscle\": muscle_name,\n",
    "            \"Calibrated_MaxIsometricForce\": cal_max_iso_force,\n",
    "            \"Uncalibrated_MaxIsometricForce\": ucal_max_iso_force,\n",
    "            \"Calibrated_TendonSlackLength\": cal_tendon_slack_length,\n",
    "            \"Uncalibrated_TendonSlackLength\": ucal_tendon_slack_length\n",
    "        })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Display the comparison\n",
    "print(comparison_df)\n",
    "\n",
    "# make some plots\n",
    "# Plot comparison of maxIsometricForce\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(comparison_df[\"Calibrated_MaxIsometricForce\"], comparison_df[\"Uncalibrated_MaxIsometricForce\"], 'o')\n",
    "plt.xlabel(\"Calibrated Max Isometric Force (N)\")\n",
    "plt.ylabel(\"Uncalibrated Max Isometric Force (N)\")\n",
    "\n",
    "# Plot comparison of tendonSlackLength\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(comparison_df[\"Calibrated_TendonSlackLength\"], comparison_df[\"Uncalibrated_TendonSlackLength\"], 'o')\n",
    "plt.xlabel(\"Calibrated Tendon Slack Length (m)\")\n",
    "plt.ylabel(\"Uncalibrated Tendon Slack Length (m)\")\n",
    "# Save the graph to the folder where calibrated and uncalibrated subjects are\n",
    "def save_comparison_graph(cal_model_path, ucal_model_path, fig):\n",
    "    # Determine the directory to save the graph\n",
    "    save_dir = os.path.dirname(cal_model_path)\n",
    "    save_path = os.path.join(save_dir, \"ucal-cal.png\")\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Graph saved at: {save_path}\")\n",
    "\n",
    "# Create a figure for the plots\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot comparison of maxIsometricForce\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(comparison_df[\"Calibrated_MaxIsometricForce\"], comparison_df[\"Uncalibrated_MaxIsometricForce\"], 'o')\n",
    "ax1.set_xlabel(\"Calibrated Max Isometric Force (N)\")\n",
    "ax1.set_ylabel(\"Uncalibrated Max Isometric Force (N)\")\n",
    "ax1.set_title(\"Max Isometric Force Comparison\")\n",
    "\n",
    "# Plot comparison of tendonSlackLength\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(comparison_df[\"Calibrated_TendonSlackLength\"], comparison_df[\"Uncalibrated_TendonSlackLength\"], 'o')\n",
    "ax2.set_xlabel(\"Calibrated Tendon Slack Length (m)\")\n",
    "ax2.set_ylabel(\"Uncalibrated Tendon Slack Length (m)\")\n",
    "ax2.set_title(\"Tendon Slack Length Comparison\")\n",
    "\n",
    "# Save the graph\n",
    "save_comparison_graph(cal_model, uncal_model, fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
